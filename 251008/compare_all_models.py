import os
import numpy as np
import pandas as pd
import json
import matplotlib.pyplot as plt
import tensorflow as tf
import pickle
from sklearn.metrics import accuracy_score, mean_squared_error
import importlib
from datetime import datetime  # æ–°å¢ï¼šæ™‚é–“æˆ³ç”¨

# æª¢æŸ¥æ˜¯å¦å®‰è£äº† tabulate å¥—ä»¶
TABULATE_AVAILABLE = importlib.util.find_spec("tabulate") is not None

# --- è§£æ±º matplotlib ä¸­æ–‡å­—é«”å•é¡Œçš„ä¿®æ”¹ ---
try:
    # å˜—è©¦ä½¿ç”¨ä¸­æ–‡å­—é«”
    plt.rcParams['font.family'] = ['Microsoft JhengHei', 'SimSun']  # æ·»åŠ å¾Œå‚™å­—é«”
    plt.rcParams['axes.unicode_minus'] = False  # æ­£å¸¸é¡¯ç¤ºè² è™Ÿ
    
    # æ¸¬è©¦å­—é«”æ˜¯å¦æ”¯æ´ç‰¹æ®Šç¬¦è™Ÿ
    import matplotlib.font_manager as fm
    available_fonts = [f.name for f in fm.fontManager.ttflist]
    if 'Microsoft JhengHei' not in available_fonts:
        print("è­¦å‘Š: æœªæ‰¾åˆ° Microsoft JhengHei å­—é«”ï¼Œä½¿ç”¨é è¨­å­—é«”")
        plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
    
except Exception as e:
    print(f"è­¦å‘Š: å­—é«”è¨­å®šå¤±æ•—: {e}ï¼Œä½¿ç”¨é è¨­å­—é«”")
    plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False
# ---------------------------------------------


# è‡ªå®šç¾©æ ¼å¼åŒ–è¡¨æ ¼å‡½æ•¸ï¼Œåœ¨æ²’æœ‰ tabulate æ™‚ä½¿ç”¨
def format_table(df):
    """
    æ ¼å¼åŒ– DataFrame ç‚ºç°¡å–®çš„è¡¨æ ¼æ–‡å­—
    ç•¶ç³»çµ±ä¸­æ²’æœ‰ tabulate å¥—ä»¶æ™‚ï¼Œç”¨é€™å€‹å‡½æ•¸ä»£æ›¿ to_markdown()
    """
    cols = df.columns
    header = " | ".join(str(c) for c in cols)
    separator = "-" * len(header)
    rows = []
    
    for _, row in df.iterrows():
        formatted_values = []
        for col in cols:
            val = row[col]
            if isinstance(val, (int, np.integer)):
                formatted_values.append(f"{val}")
            elif isinstance(val, (float, np.floating)):
                formatted_values.append(f"{val:.4f}")
            else:
                formatted_values.append(str(val))
        
        rows.append(" | ".join(formatted_values))
    
    return header + "\n" + separator + "\n" + "\n".join(rows)

class ModelComparison:
    """WiFi å®¤å…§å®šä½æ¨¡å‹æ¯”è¼ƒé¡"""
    
    def __init__(self, data_dir='./hadnn_data', models_to_compare=None):
        """
        åˆå§‹åŒ–æ¨¡å‹æ¯”è¼ƒå™¨
        
        åƒæ•¸:
            data_dir: æ¸¬è©¦è³‡æ–™ç›®éŒ„
            models_to_compare: è¦æ¯”è¼ƒçš„æ¨¡å‹åˆ—è¡¨ï¼Œæ¯é …åŒ…å« {name, path, type}
        """
        self.data_dir = data_dir
        
        # é è¨­æ¨¡å‹åˆ—è¡¨ï¼Œå°‡ TFLite æ¨¡å‹é¡å‹æ¨™è¨˜ç‚º 'tflite'
        if models_to_compare is None:
            models_to_compare = [
                {
                    'name': 'original HADNN',
                    'path': './models/original_hadnn.h5',
                    'type': 'keras'
                },
                {
                    'name': 'mlp',
                    'path': './models/mlp.h5',
                    'type': 'keras'
                },
                {
                    'name': 'hadnn+rf',
                    'path': './models/hadnn_n_random_forest.h5',
                    'type': 'keras'
                },
                {
                    'name': 'original hadnn tflite',
                    'path': './models/original_hadnn.tflite',
                    'type': 'tflite'
                },
                {
                    'name': 'mlp tflite',
                    'path': './models/mlp.tflite',
                    'type': 'tflite'
                },
                {
                    'name': 'hadnn+rf tflite',
                    'path': './models/hadnn_n_random_forest.tflite',
                    'type': 'tflite'
                },
            ]
        
        self.models_to_compare = models_to_compare
        self.results = {}
        self.test_data = None
        
    def load_test_data(self):
        """è¼‰å…¥æ¸¬è©¦è³‡æ–™"""
        print("è¼‰å…¥æ¸¬è©¦è³‡æ–™...")
        try:
            self.test_x = np.load(os.path.join(self.data_dir, 'test_x.npy'))
            self.test_b = np.load(os.path.join(self.data_dir, 'test_b.npy'))
            self.test_c = np.load(os.path.join(self.data_dir, 'test_c.npy'))
            self.test_y = np.load(os.path.join(self.data_dir, 'test_y.npy'))
            
            self.test_b = self.test_b.reshape(-1)
            
            if len(self.test_c.shape) == 1:
                if self.test_c.shape[0] % 2 == 0 and self.test_c.shape[0] // 2 == self.test_x.shape[0]:
                    half_len = self.test_c.shape[0] // 2
                    self.test_c = np.column_stack((self.test_c[:half_len], self.test_c[half_len:]))
                else:
                    from_test_y = False
                    try:
                        self.test_f = np.load(os.path.join(self.data_dir, 'test_f.npy'))
                        self.test_f = self.test_f.reshape(-1)
                    except:
                        self.test_f = self.test_y
                        from_test_y = True
                    
                    if not from_test_y:
                        self.test_c = self.test_y.reshape(-1, 2) if len(self.test_y.shape) > 1 else self.test_c
            
            from original_hadnn import advanced_data_preprocessing
            # åŸå§‹æ¸¬è©¦è³‡æ–™çš„é è™•ç†
            self.test_x_enhanced, _ = advanced_data_preprocessing(self.test_x)
            
            config_path = os.path.join(self.data_dir, 'dataset_config.json')
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    self.config = json.load(f)
            else:
                self.config = {
                    'building_mapping': {},
                    'floor_mapping': {}
                }
                
            print(f"æ¸¬è©¦è³‡æ–™å½¢ç‹€: x={self.test_x.shape}, b={self.test_b.shape}, c={self.test_c.shape}")
            return True
                
        except Exception as e:
            print(f"è¼‰å…¥æ¸¬è©¦è³‡æ–™å¤±æ•—: {e}")
            return False
            
    def simulate_data_corruption(self, noise_level=0, missing_rate=0, random_seed=42):
        """
        æ¨¡æ“¬è³‡æ–™æå£ï¼ŒåŒ…æ‹¬å¢åŠ é«˜æ–¯é›œè¨Šå’Œéš¨æ©Ÿç§»é™¤è³‡æ–™é»ã€‚
        
        åƒæ•¸:
            noise_level (float): é«˜æ–¯é›œè¨Šçš„æ¨™æº–å·® (dB)ã€‚
            missing_rate (float): è³‡æ–™éºå¤±çš„ç™¾åˆ†æ¯” (0-1)ã€‚
            random_seed (int): éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿çµæœå¯é‡ç¾
            
        å›å‚³:
            np.array: ç¶“æ¨¡æ“¬æå£å¾Œçš„æ¸¬è©¦è³‡æ–™ã€‚
        """
        # è¨­ç½®éš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿æ¯æ¬¡é‹è¡Œçµæœä¸€è‡´
        np.random.seed(random_seed)
        
        corrupted_test_x = self.test_x.copy()
        
        # ä¿å­˜åŸå§‹æ•¸æ“šçµ±è¨ˆä¿¡æ¯ç”¨æ–¼é©—è­‰
        original_mean = np.mean(corrupted_test_x)
        original_std = np.std(corrupted_test_x)
        
        # 1. å¢åŠ é«˜æ–¯é›œè¨Š
        if noise_level > 0:
            # ä½¿ç”¨ç‰¹å®šé›œè¨Šç´šåˆ¥å‰µå»ºå¹²æ“¾
            noise = np.random.normal(0, noise_level, corrupted_test_x.shape)
            
            # ç´€éŒ„æ·»åŠ çš„é›œè¨Šç‰¹æ€§ï¼Œç”¨æ–¼é©—è­‰
            noise_mean = np.mean(noise)
            noise_std = np.std(noise)
            noise_max = np.max(np.abs(noise))
            
            # æ‡‰ç”¨é›œè¨Š
            corrupted_test_x = corrupted_test_x + noise
            
            # ç¢ºä¿ RSSI å€¼ä¿æŒåœ¨åˆç†ç¯„åœå…§
            corrupted_test_x = np.clip(corrupted_test_x, -120, -30)
            
            # é©—è­‰é›œè¨Šæ˜¯å¦æœ‰æ•ˆæ‡‰ç”¨
            after_mean = np.mean(corrupted_test_x)
            after_std = np.std(corrupted_test_x)
            
            # è¼¸å‡ºé›œè¨Šå½±éŸ¿çµ±è¨ˆ
            print(f"  é›œè¨Šé©—è­‰ - ç´šåˆ¥: {noise_level}dB")
            print(f"    åŸå§‹æ•¸æ“š: å¹³å‡={original_mean:.2f}, æ¨™æº–å·®={original_std:.2f}")
            print(f"    é›œè¨Šç‰¹æ€§: å¹³å‡={noise_mean:.2f}, æ¨™æº–å·®={noise_std:.2f}, æœ€å¤§å€¼={noise_max:.2f}")
            print(f"    æ‡‰ç”¨å¾Œ: å¹³å‡={after_mean:.2f}, æ¨™æº–å·®={after_std:.2f}")
            print(f"    è®ŠåŒ–é‡: â–³å¹³å‡={after_mean-original_mean:.2f}, â–³æ¨™æº–å·®={after_std-original_std:.2f}")
            
            # æ•¸æ“šå·®ç•°æ¯”ä¾‹ï¼Œç”¨æ–¼ç¢ºèªä¸åŒç´šåˆ¥çš„é›œè¨Šç”¢ç”Ÿä¸åŒå½±éŸ¿
            diff_ratio = np.mean(np.abs(corrupted_test_x - self.test_x)) / np.abs(original_mean)
            print(f"    æ•¸æ“šå·®ç•°æ¯”ä¾‹: {diff_ratio:.4f}")
                
        # 2. æ¨¡æ“¬è³‡æ–™éºå¤±
        if missing_rate > 0:
            num_missing = int(np.prod(corrupted_test_x.shape) * missing_rate)
            missing_indices = np.random.choice(corrupted_test_x.size, num_missing, replace=False)
            corrupted_test_x.flat[missing_indices] = -120  # ç”¨ä¸€å€‹æ¥µç«¯å€¼ä»£è¡¨éºå¤±
            
            print(f"  éºå¤±ç‡é©—è­‰ - æ¯”ä¾‹: {missing_rate:.2%}")
            print(f"    æ‡‰æ›¿æ›é»æ•¸: {num_missing}/{corrupted_test_x.size}")
            print(f"    æ¥µç«¯å€¼æ¯”ä¾‹: {np.sum(corrupted_test_x == -120) / corrupted_test_x.size:.2%}")
            
        return corrupted_test_x

    def load_and_evaluate_model(self, model_info, input_data):
        """è¼‰å…¥ä¸¦è©•ä¼°å–®å€‹æ¨¡å‹"""
        name = model_info['name']
        path = model_info['path']
        model_type = model_info['type']
        
        print(f"\nè©•ä¼°æ¨¡å‹: {name} ({path})")
        
        if not os.path.exists(path):
            print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ {path}")
            return None
        
        try:
            if model_type == 'keras':
                from original_hadnn import AttentionLayer
                custom_objects = {'AttentionLayer': AttentionLayer}
                model = tf.keras.models.load_model(path, custom_objects=custom_objects)
                
                predictions = model.predict(input_data)
                
                if isinstance(predictions, list):
                    building_preds = np.argmax(predictions[0], axis=1)
                    floor_preds = np.argmax(predictions[1], axis=1) if len(predictions) > 1 else np.zeros_like(self.test_b)
                    position_preds = predictions[2] if len(predictions) > 2 else np.zeros((len(self.test_x), 2))
                else:
                    building_preds = np.zeros_like(self.test_b)
                    floor_preds = np.zeros_like(self.test_b)
                    position_preds = predictions
            
            elif model_type == 'tflite':
                # è¼‰å…¥ TFLite æ¨¡å‹ä¸¦å»ºç«‹æ¨è«–å™¨
                interpreter = tf.lite.Interpreter(model_path=path)
                interpreter.allocate_tensors()
                
                # å–å¾—è¼¸å…¥å’Œè¼¸å‡ºå¼µé‡çš„è©³ç´°è³‡è¨Š
                input_details = interpreter.get_input_details()
                output_details = interpreter.get_output_details()
                
                print(f"  TFLite æ¨¡å‹è©³ç´°è³‡è¨Š:")
                print(f"    è¼¸å…¥å½¢ç‹€: {input_details[0]['shape']}")
                print(f"    è¼¸å‡ºæ•¸é‡: {len(output_details)}")
                
                # ä¿®æ­£ï¼šæ›´æº–ç¢ºçš„è¼¸å‡ºæ˜ å°„é‚è¼¯
                output_shapes = [detail['shape'][1] for detail in output_details]
                output_names = [detail.get('name', f'output_{i}') for i, detail in enumerate(output_details)]
                print(f"    è¼¸å‡ºå½¢ç‹€: {output_shapes}")
                print(f"    è¼¸å‡ºåç¨±: {output_names}")
                
                # æ™ºèƒ½è¼¸å‡ºæ˜ å°„ - å„ªå…ˆä½¿ç”¨åç¨±ï¼Œç„¶å¾Œä½¿ç”¨å½¢ç‹€
                building_idx = floor_idx = position_idx = None
                
                # é¦–å…ˆåŸºæ–¼è¼¸å‡ºåç¨±æ˜ å°„
                for i, name in enumerate(output_names):
                    name_lower = name.lower()
                    if 'building' in name_lower:
                        building_idx = i
                    elif 'floor' in name_lower:
                        floor_idx = i
                    elif 'position' in name_lower:
                        position_idx = i
                
                # å¦‚æœåç¨±æ˜ å°„å¤±æ•—ï¼Œä½¿ç”¨å½¢ç‹€æ˜ å°„
                if building_idx is None or floor_idx is None or position_idx is None:
                    print("    ä½¿ç”¨å½¢ç‹€é€²è¡Œè¼¸å‡ºæ˜ å°„...")
                    # å¾é…ç½®ä¸­ç²å–æ­£ç¢ºçš„é¡åˆ¥æ•¸
                    expected_buildings = self.config.get('n_buildings', 3)
                    expected_floors = self.config.get('n_floors', 5)
                    
                    for i, shape in enumerate(output_shapes):
                        if shape == expected_buildings and building_idx is None:
                            building_idx = i
                        elif shape == expected_floors and floor_idx is None:
                            floor_idx = i
                        elif shape == 2 and position_idx is None:  # ä½ç½®åº§æ¨™
                            position_idx = i
                
                # å¦‚æœä»ç„¶ç„¡æ³•æ˜ å°„ï¼Œä½¿ç”¨é è¨­é †åº
                if building_idx is None:
                    building_idx = 0
                if floor_idx is None:
                    floor_idx = 1 if len(output_details) > 1 else 0
                if position_idx is None:
                    position_idx = 2 if len(output_details) > 2 else (1 if len(output_details) > 1 else 0)
                
                print(f"    æœ€çµ‚æ˜ å°„ - å»ºç¯‰ç‰©: {building_idx}, æ¨“å±¤: {floor_idx}, ä½ç½®: {position_idx}")
                
                # æ‰¹æ¬¡è™•ç†é æ¸¬
                batch_size = 32  # å¢åŠ æ‰¹æ¬¡å¤§å°æé«˜æ•ˆç‡
                total_samples = input_data.shape[0]
                
                building_preds_list = []
                floor_preds_list = []
                position_preds_list = []
                
                for start_idx in range(0, total_samples, batch_size):
                    end_idx = min(start_idx + batch_size, total_samples)
                    batch_data = input_data[start_idx:end_idx]
                    
                    batch_building = []
                    batch_floor = []
                    batch_position = []
                    
                    for i in range(batch_data.shape[0]):
                        # ç¢ºä¿è¼¸å…¥æ•¸æ“šé¡å‹æ­£ç¢º
                        sample_input = batch_data[i:i+1].astype(input_details[0]['dtype'])
                        
                        # æª¢æŸ¥è¼¸å…¥å½¢ç‹€
                        expected_shape = input_details[0]['shape']
                        if sample_input.shape[1] != expected_shape[1]:
                            if sample_input.shape[1] > expected_shape[1]:
                                sample_input = sample_input[:, :expected_shape[1]]
                            elif sample_input.shape[1] < expected_shape[1]:
                                padded = np.zeros((1, expected_shape[1]), dtype=sample_input.dtype)
                                padded[:, :sample_input.shape[1]] = sample_input
                                sample_input = padded
                        
                        interpreter.set_tensor(input_details[0]['index'], sample_input)
                        interpreter.invoke()
                        
                        # ç²å–æ‰€æœ‰è¼¸å‡º
                        outputs = []
                        for output_detail in output_details:
                            output = interpreter.get_tensor(output_detail['index'])
                            outputs.append(output[0])  # å»æ‰ batch ç¶­åº¦
                        
                        # æ ¹æ“šæ˜ å°„è§£æè¼¸å‡º
                        if building_idx < len(outputs):
                            building_output = outputs[building_idx]
                            batch_building.append(np.argmax(building_output))
                        else:
                            batch_building.append(0)
                        
                        if floor_idx < len(outputs):
                            floor_output = outputs[floor_idx]
                            batch_floor.append(np.argmax(floor_output))
                        else:
                            batch_floor.append(0)
                        
                        if position_idx < len(outputs):
                            position_output = outputs[position_idx]
                            if len(position_output) >= 2:
                                batch_position.append(position_output[:2])
                            else:
                                batch_position.append([position_output[0] if len(position_output) > 0 else 0.0, 0.0])
                        else:
                            batch_position.append([0.0, 0.0])
                    
                    building_preds_list.extend(batch_building)
                    floor_preds_list.extend(batch_floor)
                    position_preds_list.extend(batch_position)

                building_preds = np.array(building_preds_list)
                floor_preds = np.array(floor_preds_list)
                position_preds = np.array(position_preds_list)
                
                # é©—è­‰é æ¸¬çµæœçš„åˆç†æ€§
                print(f"    é æ¸¬çµæœçµ±è¨ˆ:")
                print(f"      å»ºç¯‰ç‰©é æ¸¬ç¯„åœ: {building_preds.min()} - {building_preds.max()}")
                print(f"      æ¨“å±¤é æ¸¬ç¯„åœ: {floor_preds.min()} - {floor_preds.max()}")
                print(f"      ä½ç½®é æ¸¬ç¯„åœ: x=[{position_preds[:,0].min():.2f}, {position_preds[:,0].max():.2f}], y=[{position_preds[:,1].min():.2f}, {position_preds[:,1].max():.2f}]")

            else:
                print(f"ä¸æ”¯æ´çš„æ¨¡å‹é¡å‹: {model_type}")
                return None
            
            building_accuracy = accuracy_score(self.test_b, building_preds)
            try:
                if hasattr(self, 'test_f'):
                    # ä¿®æ”¹ï¼šåªè€ƒæ…®å»ºç¯‰ç‰©é æ¸¬æ­£ç¢ºçš„æ¨£æœ¬è¨ˆç®—æ¨“å±¤æº–ç¢ºç‡
                    correct_building_mask = (building_preds == self.test_b)
                    if np.any(correct_building_mask):
                        floor_true = self.test_f[correct_building_mask]
                        floor_pred = floor_preds[correct_building_mask]
                        floor_accuracy = accuracy_score(floor_true, floor_pred)
                    else:
                        floor_accuracy = 0
                else:
                    # ä¿®æ”¹ï¼šåªè€ƒæ…®å»ºç¯‰ç‰©é æ¸¬æ­£ç¢ºçš„æ¨£æœ¬è¨ˆç®—æ¨“å±¤æº–ç¢ºç‡
                    correct_building_mask = (building_preds == self.test_b)
                    if np.any(correct_building_mask):
                        floor_true = self.test_y[correct_building_mask]
                        floor_pred = floor_preds[correct_building_mask]
                        floor_accuracy = accuracy_score(floor_true, floor_pred)
                    else:
                        floor_accuracy = 0
            except:
                floor_accuracy = 0
            
            position_mse = mean_squared_error(self.test_c, position_preds)
            position_rmse = np.sqrt(position_mse)
            
            euclidean_distances = np.sqrt(np.sum((self.test_c - position_preds)**2, axis=1))
            mean_error = np.mean(euclidean_distances)
            median_error = np.median(euclidean_distances)
            std_error = np.std(euclidean_distances)
            
            # æ–°å¢ï¼šè¨ˆç®—æ¢ä»¶ä½ç½®èª¤å·®ï¼ˆåªé‡å°å»ºç¯‰ç‰©å’Œæ¨“å±¤éƒ½é æ¸¬æ­£ç¢ºçš„æ¨£æœ¬ï¼‰
            try:
                if hasattr(self, 'test_f'):
                    floor_true = self.test_f
                else:
                    floor_true = self.test_y
                
                # æ‰¾å‡ºå»ºç¯‰ç‰©å’Œæ¨“å±¤éƒ½é æ¸¬æ­£ç¢ºçš„æ¨£æœ¬
                correct_building = (building_preds == self.test_b)
                correct_floor = (floor_preds == floor_true)
                correct_both = correct_building & correct_floor
                
                if np.any(correct_both):
                    conditional_distances = euclidean_distances[correct_both]
                    conditional_mean_error = np.mean(conditional_distances)
                    conditional_median_error = np.median(conditional_distances)
                    conditional_count = np.sum(correct_both)
                    
                    print(f"    æ¢ä»¶ä½ç½®èª¤å·®ï¼ˆå»ºç¯‰ç‰©+æ¨“å±¤éƒ½æ­£ç¢ºçš„æ¨£æœ¬ï¼‰:")
                    print(f"      æ¨£æœ¬æ•¸: {conditional_count}/{len(euclidean_distances)} ({conditional_count/len(euclidean_distances)*100:.1f}%)")
                    print(f"      å¹³å‡èª¤å·®: {conditional_mean_error:.4f} å…¬å°º")
                    print(f"      ä¸­ä½æ•¸èª¤å·®: {conditional_median_error:.4f} å…¬å°º")
                else:
                    conditional_mean_error = float('inf')
                    conditional_median_error = float('inf')
                    conditional_count = 0
                    print(f"    è­¦å‘Š: æ²’æœ‰å»ºç¯‰ç‰©å’Œæ¨“å±¤éƒ½é æ¸¬æ­£ç¢ºçš„æ¨£æœ¬")
                    
            except Exception as e:
                print(f"    æ¢ä»¶ä½ç½®èª¤å·®è¨ˆç®—å¤±æ•—: {e}")
                conditional_mean_error = mean_error
                conditional_median_error = median_error
                conditional_count = len(euclidean_distances)
            
            result = {
                'building_accuracy': building_accuracy,
                'floor_accuracy': floor_accuracy,
                'position_mean_error': mean_error,
                'position_median_error': median_error,
                'position_std_error': std_error,
                'position_rmse': position_rmse,
                # æ–°å¢æ¢ä»¶ä½ç½®èª¤å·®æŒ‡æ¨™
                'conditional_position_mean_error': conditional_mean_error,
                'conditional_position_median_error': conditional_median_error,
                'conditional_correct_count': conditional_count,
                'predictions': {
                    'building': building_preds.tolist(),
                    'floor': floor_preds.tolist(),
                    'position': position_preds.tolist()
                }
            }
            
            print("æ¨¡å‹è©•ä¼°å®Œæˆ:")
            print(f"  å»ºç¯‰ç‰©åˆ†é¡æº–ç¢ºç‡: {result['building_accuracy'] * 100:.4f}%")
            print(f"  æ¨“å±¤åˆ†é¡æº–ç¢ºç‡(å»ºç¯‰ç‰©æ­£ç¢ºæ™‚): {result['floor_accuracy'] * 100:.4f}%")
            print(f"  æ•´é«”ä½ç½®é æ¸¬å¹³å‡èª¤å·®: {result['position_mean_error']:.4f}")
            print(f"  æ¢ä»¶ä½ç½®é æ¸¬å¹³å‡èª¤å·®: {result['conditional_position_mean_error']:.4f}")
            
            return result
        except Exception as e:
            print(f"è©•ä¼°æ¨¡å‹ {name} å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def compare_models(self):
        """åŸ·è¡Œæ‰€æœ‰æ¨¡å‹çš„æ¯”è¼ƒï¼Œä¸¦åŠ å…¥ç©©å¥æ€§æ¸¬è©¦"""
        # åœ¨é–‹å§‹å‰é—œé–‰æ‰€æœ‰åœ–è¡¨
        plt.close('all')
        
        if not self.load_test_data():
            print("ç„¡æ³•åŸ·è¡Œæ¯”è¼ƒï¼Œå› ç‚ºæ¸¬è©¦è³‡æ–™è¼‰å…¥å¤±æ•—ã€‚")
            return
            
        # å®šç¾©ç©©å¥æ€§æ¸¬è©¦æƒ…å¢ƒ
        robustness_scenarios = {
            'åŸå§‹è³‡æ–™': {'noise': 0, 'missing_rate': 0},
            # 'é«˜æ–¯é›œè¨Š 1dB': {'noise': 1, 'missing_rate': 0},
            # 'é«˜æ–¯é›œè¨Š 2dB': {'noise': 2, 'missing_rate': 0},
            # 'é«˜æ–¯é›œè¨Š 3dB': {'noise': 3, 'missing_rate': 0},
            # 'é«˜æ–¯é›œè¨Š 4dB': {'noise': 4, 'missing_rate': 0},
            # 'é«˜æ–¯é›œè¨Š 5dB': {'noise': 5, 'missing_rate': 0},
            # 'é«˜æ–¯é›œè¨Š 6dB': {'noise': 6, 'missing_rate': 0},
            # 'é«˜æ–¯é›œè¨Š 7dB': {'noise': 7, 'missing_rate': 0},
            # 'é«˜æ–¯é›œè¨Š 8dB': {'noise': 8, 'missing_rate': 0},
            # 'é«˜æ–¯é›œè¨Š 9dB': {'noise': 9, 'missing_rate': 0},
            # 'é«˜æ–¯é›œè¨Š 10dB': {'noise': 10, 'missing_rate': 0},
            'è¨­å‚™æ•…éšœ 5%': {'noise': 0, 'missing_rate': 0.05},
            # 'è¨­å‚™æ•…éšœ 10%': {'noise': 0, 'missing_rate': 0.1},
            # 'è¨­å‚™æ•…éšœ 15%': {'noise': 0, 'missing_rate': 0.15},
            # 'è¨­å‚™æ•…éšœ 20%': {'noise': 0, 'missing_rate': 0.2},
            # 'è¨­å‚™æ•…éšœ 25%': {'noise': 0, 'missing_rate': 0.25},
            # 'è¨­å‚™æ•…éšœ 30%': {'noise': 0, 'missing_rate': 0.3},
            # 'è¨­å‚™æ•…éšœ 35%': {'noise': 0, 'missing_rate': 0.35},
            # 'é›œè¨Š 1db + æ•…éšœ 10%': {'noise': 1, 'missing_rate': 0.1},
            # 'é›œè¨Š 2db + æ•…éšœ 10%': {'noise': 2, 'missing_rate': 0.1},
            # 'é›œè¨Š 3db + æ•…éšœ 10%': {'noise': 3, 'missing_rate': 0.1},
            # 'é›œè¨Š 4db + æ•…éšœ 10%': {'noise': 4, 'missing_rate': 0.1},
            # 'é›œè¨Š 5dB + æ•…éšœ 10%': {'noise': 5, 'missing_rate': 0.1},
            # 'é›œè¨Š 10dB + æ•…éšœ 20%': {'noise': 10, 'missing_rate': 0.2}
            'é›œè¨Š 4db + æ•…éšœ 10%': {'noise': 4, 'missing_rate': 0.1},
            'é›œè¨Š 7db + æ•…éšœ 10%': {'noise': 7, 'missing_rate': 0.1},
            'é›œè¨Š 10db + æ•…éšœ 10%': {'noise': 10, 'missing_rate': 0.1},
            
        }
        
        # è¨­å®šå¤šæ¬¡æ¸¬è©¦åƒæ•¸
        num_trials = 5  # æ¯å€‹æƒ…å¢ƒæ¸¬è©¦5æ¬¡
        
        full_results = {}
        
        for scenario_name, params in robustness_scenarios.items():
            print(f"\n--- åŸ·è¡Œæƒ…å¢ƒ: {scenario_name} ({num_trials}æ¬¡æ¸¬è©¦) ---")
            print(f"åƒæ•¸: é›œè¨Š={params['noise']}dB, æ•…éšœç‡={params['missing_rate']:.1%}")
            
            scenario_results = {}  # å­˜å„²æ‰€æœ‰è©¦é©—çµæœ (æ¯å€‹æ¨¡å‹å°æ‡‰å¤šå€‹ trial)
            
            # æ·»åŠ æª¢é©—é»ï¼šç‚ºæ¯å€‹æƒ…å¢ƒç”Ÿæˆå”¯ä¸€æ¨™è­˜ç¬¦ï¼Œç¢ºä¿çµæœä¸æœƒæ··æ·†
            scenario_id = f"{scenario_name}_noise{params['noise']}_missing{params['missing_rate']}"
            print(f"  æƒ…å¢ƒID: {scenario_id}")
            
            # æ‰€æœ‰æƒ…å¢ƒéƒ½é€²è¡Œç›¸åŒæ¬¡æ•¸çš„æ¸¬è©¦ï¼Œä»¥ç²å¾—çµ±è¨ˆä¸€è‡´æ€§
            for trial in range(num_trials):
                print(f"  åŸ·è¡Œç¬¬ {trial + 1}/{num_trials} æ¬¡æ¸¬è©¦...")
                
                # ä½¿ç”¨ä¸åŒçš„éš¨æ©Ÿç¨®å­ï¼Œå³ä½¿æ˜¯åŸå§‹è³‡æ–™ä¹Ÿè¦æœ‰ä¸åŒç¨®å­
                # é€™æ¨£å¯ä»¥æ¨¡æ“¬æ¸¬è©¦ç’°å¢ƒçš„å¾®å°è®ŠåŒ–ï¼ˆå¦‚æ•¸å€¼ç²¾åº¦ã€è¨˜æ†¶é«”å°é½Šç­‰ï¼‰
                seed = 42 + trial * 100
                
                # æ¨¡æ“¬è³‡æ–™æå£
                corrupted_test_x = self.simulate_data_corruption(
                    noise_level=params['noise'],
                    missing_rate=params['missing_rate'],
                    random_seed=seed
                )
                
                # æ‡‰ç”¨èˆ‡åŸå§‹è³‡æ–™ç›¸åŒçš„é è™•ç†æ­¥é©Ÿ
                from original_hadnn import advanced_data_preprocessing
                corrupted_test_x_enhanced, _ = advanced_data_preprocessing(corrupted_test_x)
                
                # æ¯”è¼ƒåŸå§‹æ•¸æ“šå’Œç ´å£å¾Œæ•¸æ“šçš„å·®ç•°ï¼Œç”¨æ–¼é©—è­‰
                if trial == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡è©¦é©—ä¸­åŸ·è¡Œé©—è­‰
                    diff = np.abs(self.test_x_enhanced - corrupted_test_x_enhanced)
                    print(f"  æ•¸æ“šå·®ç•°é©—è­‰ - é›œè¨Š={params['noise']}dB, æ•…éšœç‡={params['missing_rate']:.1%}")
                    print(f"    å¹³å‡å·®ç•°: {np.mean(diff):.4f}")
                    print(f"    æœ€å¤§å·®ç•°: {np.max(diff):.4f}")
                    print(f"    å·®ç•°æ¯”ä¾‹: {np.sum(diff > 0) / np.prod(diff.shape):.2%}")
                
                trial_results = {}
                
                # å°æ¯å€‹æ¨¡å‹é€²è¡Œè©•ä¼°
                for model_info in self.models_to_compare:
                    result = self.load_and_evaluate_model(model_info, input_data=corrupted_test_x_enhanced)
                    if result is not None:
                        result['scenario_id'] = scenario_id
                        trial_results[model_info['name']] = result
                        # æ–°å¢ï¼šåœ¨ trial ç•¶ä¸‹å°±ç´¯ç©åˆ° scenario_results
                        if model_info['name'] not in scenario_results:
                            scenario_results[model_info['name']] = []
                        scenario_results[model_info['name']].append(result)

            # ç§»é™¤ï¼šåŸæœ¬åœ¨é€™è£¡æ‰ã€Œåˆä½µçµæœã€æœƒåªç•™ä¸‹æœ€å¾Œä¸€æ¬¡ trial
            # for model_name, result in trial_results.items():
            #     if model_name not in scenario_results:
            #         scenario_results[model_name] = []
            #     scenario_results[model_name].append(result)

            # è¨ˆç®—æ¯å€‹æ¨¡å‹çš„å¹³å‡çµæœå’Œæ¨™æº–å·®
            averaged_results = {}
            for model_name, trial_results in scenario_results.items():
                if not trial_results:
                    continue
                metrics = [
                    'building_accuracy', 'floor_accuracy',
                    'position_mean_error', 'position_median_error',
                    'position_std_error', 'position_rmse',
                    'conditional_position_mean_error', 'conditional_position_median_error'
                ]
                averaged_result = {}
                for metric in metrics:
                    values = []
                    for result in trial_results:
                        val = result.get(metric, 0)
                        if val != float('inf') and not np.isnan(val):
                            values.append(val)
                    if values:
                        averaged_result[metric] = np.mean(values)
                        averaged_result[f'{metric}_std'] = np.std(values) if len(values) > 1 else 0
                    else:
                        averaged_result[metric] = 0
                        averaged_result[f'{metric}_std'] = 0

                correct_counts = [result.get('conditional_correct_count', 0) for result in trial_results]
                averaged_result['conditional_correct_count'] = int(np.mean(correct_counts))
                averaged_result['conditional_correct_count_std'] = np.std(correct_counts) if len(correct_counts) > 1 else 0

                # èª¿æ•´ï¼šä¿ç•™æœ€å¾Œä¸€æ¬¡é æ¸¬çµæœä¾›åœ–è¡¨ä½¿ç”¨
                averaged_result['predictions'] = trial_results[-1]['predictions']
                # æ–°å¢ï¼šä¿ç•™æ¯æ¬¡ trial çš„åŸå§‹æŒ‡æ¨™ï¼Œä¾›æ‘˜è¦åˆ—å‡ºæ¯æ¬¡çµæœ
                averaged_result['trials'] = trial_results
                averaged_result['num_trials'] = len(trial_results)
                averaged_results[model_name] = averaged_result

            full_results[scenario_name] = averaged_results
            
            # é¡¯ç¤ºæ­¤æƒ…å¢ƒçš„çµæœæ‘˜è¦
            print(f"  æƒ…å¢ƒ {scenario_name} å®Œæˆï¼Œæ¸¬è©¦äº† {num_trials} æ¬¡")
            for model_name, result in averaged_results.items():
                building_acc = result['building_accuracy'] * 100
                building_std = result.get('building_accuracy_std', 0) * 100
                pos_error = result['position_mean_error']
                pos_std = result.get('position_mean_error_std', 0)
                
                # æ ¹æ“šæƒ…å¢ƒèª¿æ•´é¡¯ç¤ºæ ¼å¼
                if scenario_name == 'åŸå§‹è³‡æ–™':
                    if building_std < 0.01 and pos_std < 0.001:  # æ¨™æº–å·®å¾ˆå°ï¼Œé¡¯ç¤ºç‚ºç¢ºå®šæ€§çµæœ
                        print(f"    {model_name}: å»ºç¯‰ç‰©æº–ç¢ºç‡ {building_acc:.2f}%, "f"ä½ç½®èª¤å·® {pos_error:.4f} (ç¢ºå®šæ€§çµæœ)")
                    else:
                        print(f"    {model_name}: å»ºç¯‰ç‰©æº–ç¢ºç‡ {building_acc:.2f}Â±{building_std:.3f}%, "f"ä½ç½®èª¤å·® {pos_error:.4f}Â±{pos_std:.4f}")
                else:
                    print(f"    {model_name}: å»ºç¯‰ç‰©æº–ç¢ºç‡ {building_acc:.2f}Â±{building_std:.2f}%, "f"ä½ç½®èª¤å·® {pos_error:.4f}Â±{pos_std:.4f}")
        
        # é¡¯ç¤ºä¸¦ç”Ÿæˆæœ€çµ‚å ±å‘Š
        self.display_comparison(full_results)
        output_dir = './model_comparison251008'
        os.makedirs(output_dir, exist_ok=True)
        self.generate_comparison_report(full_results, output_dir)
        self.generate_comparison_charts(full_results, output_dir)
        # æ–°å¢ï¼šç”Ÿæˆç©©å¥æ€§æ‘˜è¦ Markdownï¼ˆå«æ¯æ¬¡çµæœï¼‰
        self.generate_robustness_summary(full_results, output_dir)
        
        print(f"æ¯”è¼ƒå ±å‘Šå·²ç”Ÿæˆè‡³: {output_dir}")

    def display_comparison(self, full_results):
        """é¡¯ç¤ºæ‰€æœ‰æƒ…å¢ƒä¸‹çš„æ¯”è¼ƒè¡¨æ ¼ï¼ŒåŒ…å«æ¨™æº–å·®ä¿¡æ¯"""
        if not full_results:
            print("æ²’æœ‰å¯æ¯”è¼ƒçš„çµæœã€‚")
            return
            
        for scenario_name, results in full_results.items():
            print(f"\n=== æƒ…å¢ƒ: {scenario_name} çš„æ¨¡å‹æ¯”è¼ƒçµæœ ===")
            if not results:
                print("æ­¤æƒ…å¢ƒæ²’æœ‰æˆåŠŸè©•ä¼°çš„æ¨¡å‹ã€‚")
                continue
                
            names = list(results.keys())
            building_accuracies = [results[name]['building_accuracy'] * 100 for name in names]
            building_stds = [results[name].get('building_accuracy_std', 0) * 100 for name in names]
            floor_accuracies = [results[name]['floor_accuracy'] * 100 for name in names]
            floor_stds = [results[name].get('floor_accuracy_std', 0) * 100 for name in names]
            mean_errors = [results[name]['position_mean_error'] for name in names]
            mean_error_stds = [results[name].get('position_mean_error_std', 0) for name in names]
            median_errors = [results[name]['position_median_error'] for name in names]
            std_errors = [results[name]['position_std_error'] for name in names]
            conditional_mean_errors = [results[name].get('conditional_position_mean_error', results[name]['position_mean_error']) for name in names]
            conditional_mean_error_stds = [results[name].get('conditional_position_mean_error_std', 0) for name in names]
            conditional_counts = [results[name].get('conditional_correct_count', len(results[name]['predictions']['building'])) for name in names]
            num_trials = [results[name].get('num_trials', 1) for name in names]
            
            # æ ¼å¼åŒ–å¸¶æœ‰æ¨™æº–å·®çš„å€¼
            def format_with_std(mean, std, decimals=4):
                if std > 0:
                    return f"{mean:.{decimals}f}Â±{std:.{decimals}f}"
                else:
                    return f"{mean:.{decimals}f}"
            
            df = pd.DataFrame({
                'æ¨¡å‹åç¨±': names,
                'å»ºç¯‰ç‰©æº–ç¢ºç‡ (%)': [format_with_std(acc, std, 4) for acc, std in zip(building_accuracies, building_stds)],
                'æ¨“å±¤æº–ç¢ºç‡ (%)': [format_with_std(acc, std, 4) for acc, std in zip(floor_accuracies, floor_stds)],
                'æ¢ä»¶ä½ç½®å¹³å‡èª¤å·® (å…¬å°º)': [format_with_std(err, std, 4) for err, std in zip(conditional_mean_errors, conditional_mean_error_stds)],
                'æ­£ç¢ºåˆ†é¡æ¨£æœ¬æ•¸': conditional_counts,
                'ä½ç½®ä¸­ä½æ•¸èª¤å·® (å…¬å°º)': [f"{err:.4f}" for err in median_errors],
                'ä½ç½®æ¨™æº–å·® (å…¬å°º)': [f"{err:.4f}" for err in std_errors],
                'æ¸¬è©¦æ¬¡æ•¸': num_trials
            })
            
            if TABULATE_AVAILABLE:
                from tabulate import tabulate
                print(tabulate(df, headers='keys', tablefmt='psql'))
            else:
                print(format_table(df))

    def generate_comparison_report(self, full_results, output_dir):
        """ç”Ÿæˆè©³ç´°çš„ Markdown æ ¼å¼å ±å‘Šï¼ŒåŒ…å«æ¨™æº–å·®ä¿¡æ¯å’Œåœ–ç‰‡èªªæ˜"""
        report_path = os.path.join(output_dir, 'model_comparison_report.md')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# æ¨¡å‹è©•ä¼°èˆ‡ç©©å¥æ€§æ¯”è¼ƒå ±å‘Š\n\n")
            f.write("æœ¬å ±å‘Šå°å¤šå€‹ Wi-Fi å®¤å…§å®šä½æ¨¡å‹åœ¨ä¸åŒè³‡æ–™æå£æƒ…å¢ƒä¸‹çš„æ•ˆèƒ½é€²è¡Œäº†è©•ä¼°èˆ‡æ¯”è¼ƒï¼Œæ—¨åœ¨æ¸¬è©¦æ¨¡å‹çš„ç©©å¥æ€§ã€‚\n\n")
            # f.write("**èªªæ˜**ï¼š\n")
            # f.write("- **æ•´é«”ä½ç½®èª¤å·®**ï¼šæ‰€æœ‰æ¸¬è©¦æ¨£æœ¬çš„ä½ç½®é æ¸¬èª¤å·®\n")
            # f.write("- **æ¢ä»¶ä½ç½®èª¤å·®**ï¼šåªé‡å°å»ºç¯‰ç‰©å’Œæ¨“å±¤éƒ½é æ¸¬æ­£ç¢ºçš„æ¨£æœ¬è¨ˆç®—çš„ä½ç½®èª¤å·®\n")
            # f.write("- **æ¨“å±¤æº–ç¢ºç‡**ï¼šåªé‡å°å»ºç¯‰ç‰©é æ¸¬æ­£ç¢ºçš„æ¨£æœ¬è¨ˆç®—çš„æ¨“å±¤åˆ†é¡æº–ç¢ºç‡\n")
            # f.write("- **å¤šæ¬¡æ¸¬è©¦**ï¼šæ¯å€‹æƒ…å¢ƒé€²è¡Œ 5 æ¬¡ç¨ç«‹æ¸¬è©¦ä¸¦å ±å‘Šå¹³å‡å€¼Â±æ¨™æº–å·®\n")
            # f.write("- **çµ±ä¸€æ¸¬è©¦æ¬¡æ•¸**ï¼šå³ä½¿æ˜¯åŸå§‹è³‡æ–™ä¹Ÿé€²è¡Œ 5 æ¬¡æ¸¬è©¦ï¼Œä»¥è©•ä¼°æ¨¡å‹å…§éƒ¨éš¨æ©Ÿæ€§å’Œæ•¸å€¼ç©©å®šæ€§\n\n")
            
            # # æ·»åŠ è¦–è¦ºåŒ–åœ–è¡¨èªªæ˜
            # f.write("## ğŸ“Š è¦–è¦ºåŒ–åœ–è¡¨èªªæ˜\n\n")
            # f.write("æœ¬å ±å‘ŠåŒ…å«å¤šç¨®é¡å‹çš„åœ–è¡¨ï¼Œä»¥ä¸‹æ˜¯å„é¡åœ–è¡¨çš„é–±è®€æŒ‡å—ï¼š\n\n")
            
            # f.write("### ğŸ”¹ åŸºç¤æ¯”è¼ƒåœ–è¡¨\n\n")
            # f.write("1. **åˆ†é¡æº–ç¢ºåº¦å°æ¯”åœ–** (`classification_accuracy_[æƒ…å¢ƒ].svg`)\n")
            # f.write("   - é¡¯ç¤ºå»ºç¯‰ç‰©å’Œæ¨“å±¤åˆ†é¡çš„æº–ç¢ºç‡\n")
            # f.write("   - ç¸±è»¸ï¼šæº–ç¢ºç‡ç™¾åˆ†æ¯”\n")
            # f.write("   - æ©«è»¸ï¼šä¸åŒæ¨¡å‹\n")
            # f.write("   - è—è‰²æŸ±ç‹€ï¼šå»ºç¯‰ç‰©åˆ†é¡æº–ç¢ºç‡ï¼Œæ©™è‰²æŸ±ç‹€ï¼šæ¨“å±¤åˆ†é¡æº–ç¢ºç‡\n")
            # f.write("   - æ•¸å€¼è¶Šé«˜è¡¨ç¤ºåˆ†é¡æ•ˆæœè¶Šå¥½\n\n")
            
            # f.write("2. **ä½ç½®é æ¸¬èª¤å·®å°æ¯”åœ–** (`position_errors_[æƒ…å¢ƒ].svg`)\n")
            # f.write("   - é¡¯ç¤ºå„æ¨¡å‹çš„å¹³å‡ä½ç½®é æ¸¬èª¤å·®\n")
            # f.write("   - ç¸±è»¸ï¼šèª¤å·®ï¼ˆå…¬å°ºï¼‰\n")
            # f.write("   - æ©«è»¸ï¼šä¸åŒæ¨¡å‹\n")
            # f.write("   - æ•¸å€¼è¶Šä½è¡¨ç¤ºå®šä½è¶Šç²¾ç¢º\n\n")
            
            # f.write("### ğŸ”¹ èª¤å·®åˆ†å¸ƒåœ–è¡¨\n\n")
            # f.write("3. **ç®±å‹åœ–** (`error_boxplot_[æƒ…å¢ƒ].svg`)\n")
            # f.write("   - é¡¯ç¤ºèª¤å·®çš„çµ±è¨ˆåˆ†å¸ƒç‰¹æ€§\n")
            # f.write("   - ç®±å­ï¼šä»£è¡¨ 25%-75% åˆ†ä½æ•¸ç¯„åœï¼ˆå››åˆ†ä½è· IQRï¼‰\n")
            # f.write("   - ä¸­ç·šï¼šä¸­ä½æ•¸\n")
            # f.write("   - è™›ç·šï¼šå¹³å‡å€¼\n")
            # f.write("   - è§¸é¬šï¼šå»¶ä¼¸è‡³ 1.5Ã—IQR ç¯„åœ\n")
            # f.write("   - ç´…é»ï¼šç•°å¸¸å€¼ï¼ˆè¶…å‡ºè§¸é¬šç¯„åœçš„æ¨£æœ¬ï¼‰\n")
            # f.write("   - ç®±å­è¶Šçª„è¡¨ç¤ºèª¤å·®åˆ†å¸ƒè¶Šé›†ä¸­ï¼Œç•°å¸¸å€¼è¶Šå°‘è¡¨ç¤ºæ¨¡å‹è¶Šç©©å®š\n\n")
            
            # f.write("4. **å°æç´åœ–** (`error_violin_[æƒ…å¢ƒ].svg`)\n")
            # f.write("   - çµåˆç®±å‹åœ–å’Œå¯†åº¦åˆ†å¸ƒçš„å„ªé»\n")
            # f.write("   - å¯¬åº¦ï¼šä»£è¡¨è©²èª¤å·®å€¼çš„æ¨£æœ¬å¯†åº¦\n")
            # f.write("   - å…§éƒ¨ç·šæ¢ï¼šä¸­ä½æ•¸å’Œå››åˆ†ä½æ•¸\n")
            # f.write("   - å½¢ç‹€ï¼šé¡¯ç¤ºèª¤å·®åˆ†å¸ƒçš„è©³ç´°å½¢æ…‹\n")
            # f.write("   - å°ç¨±çš„ã€Œå°æç´ã€å½¢ç‹€è¡¨ç¤ºæ­£æ…‹åˆ†å¸ƒï¼Œä¸å°ç¨±å‰‡è¡¨ç¤ºåæ–œåˆ†å¸ƒ\n\n")
            
            # f.write("5. **ç´¯ç©åˆ†å¸ƒå‡½æ•¸ï¼ˆCDFï¼‰åœ–** (`error_cdf_[æƒ…å¢ƒ].svg`)\n")
            # f.write("   - é¡¯ç¤ºé”åˆ°ç‰¹å®šèª¤å·®é–¾å€¼çš„æ¨£æœ¬ç™¾åˆ†æ¯”\n")
            # f.write("   - æ©«è»¸ï¼šèª¤å·®å€¼ï¼ˆå…¬å°ºï¼‰\n")
            # f.write("   - ç¸±è»¸ï¼šç´¯ç©ç™¾åˆ†æ¯”ï¼ˆ%ï¼‰\n")
            # f.write("   - é‡è¦é–¾å€¼ï¼š1mã€2mã€3mï¼ˆç”¨ç°è‰²è™›ç·šæ¨™ç¤ºï¼‰\n")
            # f.write("   - æ›²ç·šè¶Šé™¡å³­è¡¨ç¤ºèª¤å·®è¶Šé›†ä¸­ï¼Œå·¦ä¸Šè§’çš„æ›²ç·šè¡¨ç¤ºèª¤å·®è¶Šå°\n")
            # f.write("   - é»ç‹€æ¨™è¨˜ï¼šé¡¯ç¤ºåœ¨ 1mã€2mã€3m é–¾å€¼ä¸‹çš„ç²¾ç¢ºç™¾åˆ†æ¯”\n\n")
            
            # f.write("6. **è©³ç´°åˆ†å¸ƒç›´æ–¹åœ–** (`error_detailed_distribution_[æƒ…å¢ƒ].svg`)\n")
            # f.write("   - å­åœ–å½¢å¼é¡¯ç¤ºæ¯å€‹æ¨¡å‹çš„èª¤å·®åˆ†å¸ƒ\n")
            # f.write("   - è—è‰²æŸ±ç‹€ï¼šèª¤å·®é »ç‡åˆ†å¸ƒ\n")
            # f.write("   - ç´…è‰²è™›ç·šï¼šå¹³å‡å€¼\n")
            # f.write("   - æ©™è‰²è™›ç·šï¼šä¸­ä½æ•¸\n")
            # f.write("   - å³ä¸Šè§’æ–‡å­—ï¼šçµ±è¨ˆæ‘˜è¦ï¼ˆæ¨£æœ¬æ•¸ã€æ¨™æº–å·®ã€90%åˆ†ä½æ•¸ï¼‰\n")
            # f.write("   - åˆ†å¸ƒé›†ä¸­åœ¨å·¦å´è¡¨ç¤ºå¤§å¤šæ•¸æ¨£æœ¬èª¤å·®è¼ƒå°\n\n")
            
            # f.write("7. **çµ±è¨ˆç¸½çµè¡¨æ ¼åœ–** (`error_statistics_table_[æƒ…å¢ƒ].svg`)\n")
            # f.write("   - ä»¥è¡¨æ ¼å½¢å¼ç¸½çµå„æ¨¡å‹çš„é—œéµçµ±è¨ˆæŒ‡æ¨™\n")
            # f.write("   - å¹³å‡å€¼ï¼šæ‰€æœ‰æ¨£æœ¬çš„å¹³å‡èª¤å·®\n")
            # f.write("   - ä¸­ä½æ•¸ï¼šæ’åºå¾Œä¸­é–“å€¼çš„èª¤å·®\n")
            # f.write("   - æ¨™æº–å·®ï¼šèª¤å·®åˆ†å¸ƒçš„é›¢æ•£ç¨‹åº¦\n")
            # f.write("   - Q25/Q75ï¼š25% å’Œ 75% åˆ†ä½æ•¸\n")
            # f.write("   - P90ï¼š90% åˆ†ä½æ•¸ï¼ˆè¡¨ç¤º 90% çš„æ¨£æœ¬èª¤å·®éƒ½å°æ–¼æ­¤å€¼ï¼‰\n")
            # f.write("   - <1m/<2m/<3mï¼šèª¤å·®å°æ–¼æŒ‡å®šé–¾å€¼çš„æ¨£æœ¬ç™¾åˆ†æ¯”\n\n")
            
            # f.write("### ğŸ”¹ ç©©å¥æ€§åˆ†æåœ–è¡¨\n\n")
            # f.write("8. **è·¨æƒ…å¢ƒç©©å¥æ€§æ¸¬è©¦åœ–**\n")
            # f.write("   - `robustness_building_accuracy.svg`ï¼šå»ºç¯‰ç‰©åˆ†é¡åœ¨ä¸åŒæƒ…å¢ƒä¸‹çš„è¡¨ç¾\n")
            # f.write("   - `robustness_floor_accuracy.svg`ï¼šæ¨“å±¤åˆ†é¡åœ¨ä¸åŒæƒ…å¢ƒä¸‹çš„è¡¨ç¾\n")
            # f.write("   - `robustness_position_error.svg`ï¼šä½ç½®é æ¸¬åœ¨ä¸åŒæƒ…å¢ƒä¸‹çš„è¡¨ç¾\n")
            # f.write("   - ä¸åŒé¡è‰²æŸ±ç‹€ä»£è¡¨ä¸åŒæ¨¡å‹\n")
            # f.write("   - å¾å·¦åˆ°å³ï¼šåŸå§‹è³‡æ–™â†’é«˜æ–¯é›œè¨Šâ†’è¨­å‚™æ•…éšœâ†’è¤‡åˆå¹²æ“¾\n")
            # f.write("   - è§€å¯ŸæŸ±ç‹€é«˜åº¦çš„è®ŠåŒ–ç¨‹åº¦å¯è©•ä¼°æ¨¡å‹ç©©å¥æ€§\n\n")
            
            # f.write("9. **ç©©å¥æ€§è©•åˆ†åœ–** (`robustness_scores.svg`)\n")
            # f.write("   - ç¶œåˆè©•åˆ†ï¼Œ1.0 è¡¨ç¤ºå®Œç¾ä¿æŒåŸºæº–æ€§èƒ½\n")
            # f.write("   - è©•åˆ†è¶Šé«˜è¡¨ç¤ºåœ¨æƒ¡åŠ£æ¢ä»¶ä¸‹æ€§èƒ½ä¿æŒè¶Šå¥½\n")
            # f.write("   - åŸå§‹è³‡æ–™æƒ…å¢ƒå›ºå®šç‚º 1.0ï¼ˆåŸºæº–ï¼‰\n")
            # f.write("   - å…¶ä»–æƒ…å¢ƒçš„è©•åˆ†åæ˜ ç›¸å°æ–¼åŸºæº–çš„æ€§èƒ½ä¿æŒç‡\n\n")
            
            # f.write("### ğŸ“ˆ å¦‚ä½•è§£è®€çµæœ\n\n")
            # f.write("**é¸æ“‡æœ€ä½³æ¨¡å‹çš„åƒè€ƒåŸå‰‡ï¼š**\n\n")
            # f.write("1. **æº–ç¢ºç‡å„ªå…ˆ**ï¼šå»ºç¯‰ç‰©å’Œæ¨“å±¤åˆ†é¡æº–ç¢ºç‡è¶Šé«˜è¶Šå¥½\n")
            # f.write("2. **èª¤å·®æœ€å°åŒ–**ï¼šä½ç½®é æ¸¬èª¤å·®è¶Šå°è¶Šå¥½ï¼ˆç‰¹åˆ¥é—œæ³¨æ¢ä»¶ä½ç½®èª¤å·®ï¼‰\n")
            # f.write("3. **ç©©å®šæ€§è€ƒé‡**ï¼šç®±å‹åœ–ä¸­ç®±å­è¶Šçª„ã€ç•°å¸¸å€¼è¶Šå°‘è¡¨ç¤ºè¶Šç©©å®š\n")
            # f.write("4. **ç©©å¥æ€§è¦æ±‚**ï¼šåœ¨å¹²æ“¾æƒ…å¢ƒä¸‹æ€§èƒ½ä¸‹é™å¹…åº¦è¶Šå°è¶Šå¥½\n")
            # f.write("5. **æ‡‰ç”¨éœ€æ±‚**ï¼šæ ¹æ“šå¯¦éš›æ‡‰ç”¨å°æº–ç¢ºç‡å’Œç²¾åº¦çš„ä¸åŒè¦æ±‚æ¬Šè¡¡é¸æ“‡\n\n")
            
            # f.write("**ç•°å¸¸æƒ…æ³è­˜åˆ¥ï¼š**\n\n")
            # f.write("- CDF åœ–ä¸­æ›²ç·šéæ–¼å¹³ç·©ï¼šè¡¨ç¤ºèª¤å·®åˆ†å¸ƒéæ–¼åˆ†æ•£\n")
            # f.write("- ç®±å‹åœ–ä¸­ç•°å¸¸å€¼éå¤šï¼šè¡¨ç¤ºæ¨¡å‹é æ¸¬ä¸ç©©å®š\n")
            # f.write("- ç©©å¥æ€§è©•åˆ†æ€¥åŠ‡ä¸‹é™ï¼šè¡¨ç¤ºæ¨¡å‹å°å¹²æ“¾æ•æ„Ÿ\n")
            # f.write("- å¤šå³°åˆ†å¸ƒï¼ˆå°æç´åœ–æˆ–ç›´æ–¹åœ–ï¼‰ï¼šå¯èƒ½å­˜åœ¨ç³»çµ±æ€§åå·®\n\n")
            
            for scenario_name, results in full_results.items():
                if not results:
                    continue
                
                f.write(f"## æƒ…å¢ƒ: {scenario_name}\n\n")
                
                # æ·»åŠ æƒ…å¢ƒç‰¹å®šçš„åœ–ç‰‡èªªæ˜
                scenario_clean = scenario_name.replace(" ", "_")
                # f.write(f"### ğŸ“¸ ç›¸é—œè¦–è¦ºåŒ–åœ–è¡¨\n\n")
                # f.write(f"æ­¤æƒ…å¢ƒçš„è©³ç´°åˆ†æåœ–è¡¨åŒ…æ‹¬ï¼š\n\n")
                # f.write(f"- ğŸ“Š [åˆ†é¡æº–ç¢ºåº¦å°æ¯”](./classification_accuracy_{scenario_clean}.svg)\n")
                # f.write(f"- ğŸ“ˆ [ä½ç½®èª¤å·®å°æ¯”](./position_errors_{scenario_clean}.svg)\n")
                # f.write(f"- ğŸ“¦ [èª¤å·®ç®±å‹åœ–](./error_boxplot_{scenario_clean}.svg)\n")
                # f.write(f"- ğŸ» [èª¤å·®å¯†åº¦åˆ†å¸ƒ](./error_violin_{scenario_clean}.svg)\n")
                # f.write(f"- ğŸ“‰ [èª¤å·®ç´¯ç©åˆ†å¸ƒ](./error_cdf_{scenario_clean}.svg)\n")
                # f.write(f"- ğŸ“‹ [è©³ç´°åˆ†å¸ƒåœ–](./error_detailed_distribution_{scenario_clean}.svg)\n")
                # f.write(f"- ğŸ“‘ [çµ±è¨ˆæ‘˜è¦è¡¨](./error_statistics_table_{scenario_clean}.svg)\n\n")
                
                # æ ¹æ“šæƒ…å¢ƒæä¾›ç‰¹æ®Šè§£è®€å»ºè­°
                if scenario_name == "åŸå§‹è³‡æ–™":
                    f.write("**ğŸ“ è§£è®€é‡é»ï¼š**\n")
                    f.write("- æ­¤ç‚ºåŸºæº–æƒ…å¢ƒï¼Œå±•ç¾å„æ¨¡å‹åœ¨ç†æƒ³æ¢ä»¶ä¸‹çš„æœ€ä½³æ€§èƒ½\n")
                    f.write("- é‡é»è§€å¯Ÿå„æ¨¡å‹çš„çµ•å°æ€§èƒ½è¡¨ç¾\n")
                    f.write("- æ³¨æ„æ¢ä»¶ä½ç½®èª¤å·®èˆ‡æ•´é«”ä½ç½®èª¤å·®çš„å·®ç•°\n\n")
                elif "é›œè¨Š" in scenario_name:
                    f.write("**ğŸ“ è§£è®€é‡é»ï¼š**\n")
                    f.write("- é«˜æ–¯é›œè¨Šæ¨¡æ“¬ Wi-Fi ä¿¡è™Ÿçš„éš¨æ©Ÿæ“¾å‹•\n")
                    f.write("- è§€å¯Ÿå„æ¨¡å‹å°ä¿¡è™Ÿå™ªéŸ³çš„æŠ—å¹²æ“¾èƒ½åŠ›\n")
                    f.write("- é—œæ³¨æº–ç¢ºç‡ä¸‹é™å¹…åº¦å’Œèª¤å·®å¢åŠ ç¨‹åº¦\n\n")
                    # æ·»åŠ é›œè¨Šç´šåˆ¥å½±éŸ¿æç¤º
                    noise_level = [int(s.replace('dB', '')) for s in scenario_name.split() if s.endswith('dB')][0] if any(s.endswith('dB') for s in scenario_name.split()) else 0
                    if noise_level > 0:
                        f.write(f"- ç•¶å‰é›œè¨Šç´šåˆ¥: {noise_level}dB (è¶Šé«˜å¹²æ“¾è¶Šå¼·)\n\n")
                elif "æ•…éšœ" in scenario_name:
                    f.write("**ğŸ“ è§£è®€é‡é»ï¼š**\n")
                    f.write("- æ¨¡æ“¬ AP è¨­å‚™æ•…éšœæˆ–ä¿¡è™Ÿé®è”½æƒ…æ³\n")
                    f.write("- è©•ä¼°æ¨¡å‹åœ¨éƒ¨åˆ†ä¿¡æ¯ç¼ºå¤±æ™‚çš„è£œå„Ÿèƒ½åŠ›\n")
                    f.write("- é«˜æ•…éšœç‡ï¼ˆ50%ï¼‰æ¨¡æ“¬æ¥µç«¯æƒ¡åŠ£ç’°å¢ƒ\n\n")
                elif "+" in scenario_name:
                    f.write("**ğŸ“ è§£è®€é‡é»ï¼š**\n")
                    f.write("- è¤‡åˆå¹²æ“¾æƒ…å¢ƒï¼ŒåŒæ™‚å­˜åœ¨é›œè¨Šå’Œè¨­å‚™æ•…éšœ\n")
                    f.write("- æœ€å…·æŒ‘æˆ°æ€§çš„æ¸¬è©¦æ¢ä»¶\n")
                    f.write("- é‡é»è©•ä¼°æ¨¡å‹åœ¨å¤šé‡å£“åŠ›ä¸‹çš„ç¶œåˆè¡¨ç¾\n\n")
                
                f.write("æ­¤æƒ…å¢ƒä¸‹ï¼Œå„æ¨¡å‹è¡¨ç¾å¦‚ä¸‹ï¼š\n\n")
                
                # æ·»åŠ è¡¨æ ¼
                names = list(results.keys())
                building_accuracies = [results[name]['building_accuracy'] * 100 for name in names]
                building_stds = [results[name].get('building_accuracy_std', 0) * 100 for name in names]
                floor_accuracies = [results[name]['floor_accuracy'] * 100 for name in names]
                floor_stds = [results[name].get('floor_accuracy_std', 0) * 100 for name in names]
                mean_errors = [results[name]['position_mean_error'] for name in names]
                mean_error_stds = [results[name].get('position_mean_error_std', 0) for name in names]
                median_errors = [results[name]['position_median_error'] for name in names]
                std_errors = [results[name]['position_std_error'] for name in names]
                conditional_mean_errors = [results[name].get('conditional_position_mean_error', results[name]['position_mean_error']) for name in names]
                conditional_mean_error_stds = [results[name].get('conditional_position_mean_error_std', 0) for name in names]
                conditional_counts = [results[name].get('conditional_correct_count', len(results[name]['predictions']['building'])) for name in names]
                num_trials = [results[name].get('num_trials', 1) for name in names]
                
                # æ ¼å¼åŒ–å¸¶æœ‰æ¨™æº–å·®çš„å€¼
                def format_with_std(mean, std, decimals=4):
                    if std > 0:
                        return f"{mean:.{decimals}f}Â±{std:.{decimals}f}"
                    else:
                        return f"{mean:.{decimals}f}"
                
                df = pd.DataFrame({
                    'æ¨¡å‹åç¨±': names,
                    'å»ºç¯‰ç‰©æº–ç¢ºç‡ (%)': [format_with_std(acc, std, 4) for acc, std in zip(building_accuracies, building_stds)],
                    'æ¨“å±¤æº–ç¢ºç‡ (%)': [format_with_std(acc, std, 4) for acc, std in zip(floor_accuracies, floor_stds)],
                    'æ¢ä»¶ä½ç½®å¹³å‡èª¤å·® (å…¬å°º)': [format_with_std(err, std, 4) for err, std in zip(conditional_mean_errors, conditional_mean_error_stds)],
                    'æ­£ç¢ºåˆ†é¡æ¨£æœ¬æ•¸': conditional_counts,
                    'ä½ç½®ä¸­ä½æ•¸èª¤å·® (å…¬å°º)': [f"{err:.4f}" for err in median_errors],
                    'ä½ç½®æ¨™æº–å·® (å…¬å°º)': [f"{err:.4f}" for err in std_errors],
                    'æ¸¬è©¦æ¬¡æ•¸': num_trials
                })
                
                if TABULATE_AVAILABLE:
                    from tabulate import tabulate
                    f.write(tabulate(df, headers='keys', tablefmt='github'))
                else:
                    f.write(format_table(df))
                
                f.write("\n")
                
            # åœ¨å ±å‘Šæœ«å°¾æ·»åŠ åœ–è¡¨æ–‡ä»¶æ¸…å–®
            f.write("## ğŸ“‚ é™„éŒ„ï¼šå®Œæ•´åœ–è¡¨æ¸…å–®\n\n")
            f.write("### å„æƒ…å¢ƒå°ˆç”¨åœ–è¡¨\n\n")
            
            scenario_names = list(full_results.keys())
            for scenario_name in scenario_names:
                scenario_clean = scenario_name.replace(" ", "_")
                f.write(f"**{scenario_name}ï¼š**\n")
                f.write(f"- `classification_accuracy_{scenario_clean}.svg` - åˆ†é¡æº–ç¢ºåº¦å°æ¯”\n")
                f.write(f"- `position_errors_{scenario_clean}.svg` - ä½ç½®èª¤å·®å°æ¯”\n")
                f.write(f"- `error_boxplot_{scenario_clean}.svg` - èª¤å·®ç®±å‹åœ–\n")
                f.write(f"- `error_violin_{scenario_clean}.svg` - èª¤å·®å°æç´åœ–\n")
                f.write(f"- `error_cdf_{scenario_clean}.svg` - èª¤å·®ç´¯ç©åˆ†å¸ƒå‡½æ•¸\n")
                f.write(f"- `error_detailed_distribution_{scenario_clean}.svg` - è©³ç´°èª¤å·®åˆ†å¸ƒ\n")
                f.write(f"- `error_statistics_table_{scenario_clean}.svg` - çµ±è¨ˆæ‘˜è¦è¡¨æ ¼\n\n")
            
            f.write("### è·¨æƒ…å¢ƒåˆ†æåœ–è¡¨\n\n")
            f.write("- `robustness_building_accuracy.svg` - å»ºç¯‰ç‰©åˆ†é¡ç©©å¥æ€§æ¸¬è©¦\n")
            f.write("- `robustness_floor_accuracy.svg` - æ¨“å±¤åˆ†é¡ç©©å¥æ€§æ¸¬è©¦\n")
            f.write("- `robustness_position_error.svg` - ä½ç½®é æ¸¬ç©©å¥æ€§æ¸¬è©¦\n")
            f.write("- `robustness_scores.svg` - ç¶œåˆç©©å¥æ€§è©•åˆ†\n\n")
            
            f.write("### ğŸ“Š å»ºè­°çš„åœ–è¡¨æŸ¥çœ‹é †åº\n\n")
            f.write("1. **å¿«é€Ÿæ¦‚è¦½**ï¼šå…ˆæŸ¥çœ‹å„æƒ…å¢ƒçš„åˆ†é¡æº–ç¢ºåº¦å’Œä½ç½®èª¤å·®å°æ¯”åœ–\n")
            f.write("2. **æ·±å…¥åˆ†æ**ï¼šæŸ¥çœ‹ç®±å‹åœ–å’Œ CDF åœ–äº†è§£èª¤å·®åˆ†å¸ƒç‰¹æ€§\n")
            f.write("3. **è©³ç´°æª¢è¦–**ï¼šæŸ¥çœ‹è©³ç´°åˆ†å¸ƒåœ–å’Œçµ±è¨ˆè¡¨æ ¼ç²å–å…·é«”æ•¸å€¼\n")
            f.write("4. **ç©©å¥æ€§è©•ä¼°**ï¼šæŸ¥çœ‹è·¨æƒ…å¢ƒåœ–è¡¨äº†è§£æ¨¡å‹åœ¨ä¸åŒæ¢ä»¶ä¸‹çš„è¡¨ç¾\n")
            f.write("5. **ç¶œåˆè©•åˆ†**ï¼šåƒè€ƒç©©å¥æ€§è©•åˆ†åœ–åšå‡ºæœ€çµ‚æ±ºç­–\n\n")
            
            f.write("---")
            
        print(f"æ¯”è¼ƒå ±å‘Šå·²ä¿å­˜è‡³: {report_path}")

    def generate_comparison_charts(self, full_results, output_dir):
        """ç”Ÿæˆä¸¦ä¿å­˜åœ–è¡¨ï¼Œç‚ºæ¯å€‹æƒ…å¢ƒå‰µå»ºç¨ç«‹çš„åœ–è¡¨"""
        # åœ¨é–‹å§‹å‰é—œé–‰æ‰€æœ‰åœ–è¡¨
        plt.close('all')
        
        for scenario_name, results in full_results.items():
            if not results:
                continue

            names = list(results.keys())
            building_accuracies = [results[name]['building_accuracy'] * 100 for name in names]
            floor_accuracies = [results[name]['floor_accuracy'] * 100 for name in names]
            mean_errors = [results[name]['position_mean_error'] for name in names]

            # åˆ†é¡æº–ç¢ºåº¦åœ–è¡¨
            df_acc = pd.DataFrame({
                'å»ºç¯‰ç‰©æº–ç¢ºç‡': building_accuracies,
                'æ¨“å±¤æº–ç¢ºç‡': floor_accuracies
            }, index=names)

            try:
                fig = plt.figure(figsize=(12, 8))
                df_acc.plot(kind='bar', width=0.4, align='center')
                plt.xlabel('æ¨¡å‹')
                plt.ylabel('æº–ç¢ºç‡ (%)')
                plt.title(f'ä¸åŒæ¨¡å‹çš„åˆ†é¡æº–ç¢ºåº¦å°æ¯” - {scenario_name}')
                plt.xticks(rotation=15)
                plt.grid(axis='y', linestyle='--', alpha=0.7)
                plt.legend()
                plt.tight_layout()
                plt.savefig(os.path.join(output_dir, f'classification_accuracy_{scenario_name.replace(" ", "_")}.svg'), format='svg', bbox_inches='tight')
            finally:
                plt.close(fig)  # æ˜ç¢ºé—œé–‰ç‰¹å®šåœ–è¡¨

            # ä½ç½®èª¤å·®åœ–è¡¨
            try:
                fig = plt.figure(figsize=(12, 8))
                plt.bar(names, mean_errors, color='skyblue')
                plt.xlabel('æ¨¡å‹')
                plt.ylabel('å¹³å‡èª¤å·® (å…¬å°º)')
                plt.title(f'ä¸åŒæ¨¡å‹çš„ä½ç½®é æ¸¬å¹³å‡èª¤å·®å°æ¯” - {scenario_name}')
                plt.xticks(rotation=15)
                plt.grid(axis='y', linestyle='--', alpha=0.7)
                plt.tight_layout()
                plt.savefig(os.path.join(output_dir, f'position_errors_{scenario_name.replace(" ", "_")}.svg'), format='svg', bbox_inches='tight')
            finally:
                plt.close(fig)  # æ˜ç¢ºé—œé–‰ç‰¹å®šåœ–è¡¨

            # æ”¹é€²çš„ä½ç½®èª¤å·®åˆ†å¸ƒåœ–è¡¨
            self.generate_enhanced_error_distribution_charts(scenario_name, names, results, output_dir)

        # ç”Ÿæˆè·¨æƒ…å¢ƒæ¯”è¼ƒåœ–è¡¨
        self.generate_cross_scenario_charts(full_results, output_dir)

    def generate_enhanced_error_distribution_charts(self, scenario_name, names, results, output_dir):
        """ç”Ÿæˆå¢å¼·ç‰ˆçš„ä½ç½®èª¤å·®åˆ†å¸ƒåœ–è¡¨"""
        # åœ¨é–‹å§‹å‰é—œé–‰æ‰€æœ‰åœ–è¡¨
        plt.close('all')
        
        # æº–å‚™æ•¸æ“š
        all_errors = {}
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
        
        for i, name in enumerate(names):
            errors = np.sqrt(np.sum((self.test_c - np.array(results[name]['predictions']['position']))**2, axis=1))
            all_errors[name] = errors

        # 1. ç®±å‹åœ– (Box Plot) - é¡¯ç¤ºçµ±è¨ˆåˆ†å¸ƒ
        # try:
        #     fig = plt.figure(figsize=(14, 8))
        #     box_data = [all_errors[name] for name in names]
            
        #     box_plot = plt.boxplot(box_data, labels=names, patch_artist=True, 
        #                           showmeans=True, meanline=True,
        #                           flierprops=dict(marker='o', markerfacecolor='red', markersize=4, alpha=0.5))
            
        #     # ç‚ºç®±å‹åœ–è‘—è‰²
        #     for patch, color in zip(box_plot['boxes'], colors[:len(names)]):
        #         patch.set_facecolor(color)
        #         patch.set_alpha(0.7)
            
        #     plt.xlabel('æ¨¡å‹')
        #     plt.ylabel('ä½ç½®é æ¸¬èª¤å·® (å…¬å°º)')
        #     plt.title(f'ä½ç½®é æ¸¬èª¤å·®ç®±å‹åœ– - {scenario_name}')
        #     plt.xticks(rotation=15)
        #     plt.grid(axis='y', linestyle='--', alpha=0.7)
            
        #     # æ·»åŠ çµ±è¨ˆä¿¡æ¯
        #     for i, name in enumerate(names):
        #         errors = all_errors[name]
        #         mean_err = np.mean(errors)
        #         median_err = np.median(errors)
        #         q75_err = np.percentile(errors, 75)
        #         q25_err = np.percentile(errors, 25)
                
        #         # åœ¨åœ–ä¸Šæ·»åŠ çµ±è¨ˆä¿¡æ¯
        #         plt.text(i+1, plt.ylim()[1] * 0.95, 
        #                 f'å¹³å‡: {mean_err:.3f}\nä¸­ä½æ•¸: {median_err:.3f}\nIQR: {q75_err-q25_err:.3f}',
        #                 ha='center', va='top', fontsize=8,
        #                 bbox=dict(boxstyle='round,pad=0.3', facecolor=colors[i], alpha=0.3))
            
        #     plt.tight_layout()
        #     plt.savefig(os.path.join(output_dir, f'error_boxplot_{scenario_name.replace(" ", "_")}.svg'), format='svg', bbox_inches='tight')
        # except Exception as e:
        #     print(f"ç®±å‹åœ–ç”Ÿæˆå¤±æ•—: {e}")
        # finally:
        #     plt.close(fig)  # æ˜ç¢ºé—œé–‰ç‰¹å®šåœ–è¡¨

        # 2. å°æç´åœ– (Violin Plot) - é¡¯ç¤ºå¯†åº¦åˆ†å¸ƒ
        # try:
        #     fig = plt.figure(figsize=(14, 8))
        #     violin_parts = plt.violinplot(box_data, positions=range(1, len(names)+1), 
        #                                 showmeans=True, showmedians=True, showextrema=True)
            
        #     # ç‚ºå°æç´åœ–è‘—è‰²
        #     for i, pc in enumerate(violin_parts['bodies']):
        #         pc.set_facecolor(colors[i % len(colors)])
        #         pc.set_alpha(0.7)
            
        #     plt.xticks(range(1, len(names)+1), names, rotation=15)
        #     plt.xlabel('æ¨¡å‹')
        #     plt.ylabel('ä½ç½®é æ¸¬èª¤å·® (å…¬å°º)')
        #     plt.title(f'ä½ç½®é æ¸¬èª¤å·®å¯†åº¦åˆ†å¸ƒ - {scenario_name}')
        #     plt.grid(axis='y', linestyle='--', alpha=0.7)
        #     plt.tight_layout()
        #     plt.savefig(os.path.join(output_dir, f'error_violin_{scenario_name.replace(" ", "_")}.svg'), format='svg', bbox_inches='tight')
        # except Exception as e:
        #     print(f"å°æç´åœ–ç”Ÿæˆå¤±æ•—: {e}")
        # finally:
        #     plt.close(fig)  # æ˜ç¢ºé—œé–‰ç‰¹å®šåœ–è¡¨

        # 3. ç´¯ç©åˆ†å¸ƒå‡½æ•¸ (CDF) - é¡¯ç¤ºèª¤å·®é”åˆ°æŸé–¾å€¼çš„ç™¾åˆ†æ¯”
        try:
            fig = plt.figure(figsize=(14, 8))
            
            for i, name in enumerate(names):
                errors = all_errors[name]
                sorted_errors = np.sort(errors)
                cumulative_prob = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)
                
                plt.plot(sorted_errors, cumulative_prob * 100, 
                        label=name, color=colors[i % len(colors)], linewidth=2)
                
                # æ·»åŠ é—œéµé»æ¨™è¨˜
                for threshold in [1.0, 2.0, 3.0]:
                    if threshold <= np.max(sorted_errors):
                        percentage = np.sum(errors <= threshold) / len(errors) * 100
                        idx = np.where(sorted_errors <= threshold)[0]
                        if len(idx) > 0:
                            plt.scatter(threshold, percentage, color=colors[i % len(colors)], 
                                      s=50, zorder=5, alpha=0.8)
        
            # æ·»åŠ åƒè€ƒç·š
            for threshold in [1.0, 2.0, 3.0]:
                plt.axvline(x=threshold, color='gray', linestyle='--', alpha=0.5)
                plt.text(threshold, 5, f'{threshold}m', rotation=90, va='bottom', ha='right', fontsize=9)
            
            plt.xlabel('ä½ç½®é æ¸¬èª¤å·® (å…¬å°º)')
            plt.ylabel('ç´¯ç©ç™¾åˆ†æ¯” (%)')
            plt.title(f'ä½ç½®é æ¸¬èª¤å·®ç´¯ç©åˆ†å¸ƒå‡½æ•¸ - {scenario_name}')
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.grid(True, alpha=0.3)
            plt.xlim(left=0)
            plt.ylim(0, 100)
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, f'error_cdf_{scenario_name.replace(" ", "_")}.svg'), format='svg', bbox_inches='tight')
        except Exception as e:
            print(f"CDFåœ–ç”Ÿæˆå¤±æ•—: {e}")
        finally:
            plt.close(fig)  # æ˜ç¢ºé—œé–‰ç‰¹å®šåœ–è¡¨

        # 4. æ”¹é€²çš„ç›´æ–¹åœ– - æ›´æ¸…æ™°çš„åˆ†å¸ƒé¡¯ç¤º
        try:
            fig = plt.figure(figsize=(14, 10))
            
            # ä½¿ç”¨å­åœ–åˆ†åˆ¥é¡¯ç¤ºæ¯å€‹æ¨¡å‹
            n_models = len(names)
            rows = (n_models + 1) // 2  # æ¯è¡Œæœ€å¤š2å€‹
            cols = min(n_models, 2)
            
            for i, name in enumerate(names):
                plt.subplot(rows, cols, i + 1)
                errors = all_errors[name]
                
                # è¨ˆç®—æœ€ä½³binæ•¸é‡
                n_bins = min(30, max(10, int(np.sqrt(len(errors)))))


                # ä½¿ç”¨çµ±è¨ˆé‡è¨ˆç®— bin é‚Šç•Œ
                bin_width = 2 * (np.percentile(errors, 75) - np.percentile(errors, 25)) / (len(errors) ** (1/3))  # Freedman-Diaconis rule
                bins = np.arange(0, np.max(errors) + bin_width, bin_width)
                
                n, bins, patches = plt.hist(errors, bins=bins, alpha=0.7, 
                                       color=colors[i % len(colors)], edgecolor='black', linewidth=0.5)
                
                # æ·»åŠ çµ±è¨ˆç·š
                mean_err = np.mean(errors)
                median_err = np.median(errors)
                
                plt.axvline(mean_err, color='red', linestyle='--', linewidth=2, label=f'å¹³å‡: {mean_err:.3f}m')
                plt.axvline(median_err, color='orange', linestyle='--', linewidth=2, label=f'ä¸­ä½æ•¸: {median_err:.3f}m')
                
                plt.xlabel('èª¤å·® (å…¬å°º)')
                plt.ylabel('æ¨£æœ¬æ•¸')
                plt.title(f'{name}')
                plt.legend(fontsize=8)
                plt.grid(axis='y', linestyle='--', alpha=0.3)
                
                # æ·»åŠ çµ±è¨ˆä¿¡æ¯æ–‡å­—
                stats_text = f'æ¨£æœ¬æ•¸: {len(errors)}\næ¨™æº–å·®: {np.std(errors):.3f}m\n90%åˆ†ä½æ•¸: {np.percentile(errors, 90):.3f}m'
                plt.text(0.98, 0.98, stats_text, transform=plt.gca().transAxes, 
                        verticalalignment='top', horizontalalignment='right',
                        bbox=dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.8),
                        fontsize=8)
            
            plt.suptitle(f'å„æ¨¡å‹ä½ç½®é æ¸¬èª¤å·®è©³ç´°åˆ†å¸ƒ - {scenario_name}', fontsize=14)
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, f'error_detailed_distribution_{scenario_name.replace(" ", "_")}.svg'), format='svg', bbox_inches='tight')
        except Exception as e:
            print(f"è©³ç´°åˆ†å¸ƒåœ–ç”Ÿæˆå¤±æ•—: {e}")
        finally:
            plt.close(fig)  # æ˜ç¢ºé—œé–‰ç‰¹å®šåœ–è¡¨

        # 5. èª¤å·®çµ±è¨ˆç¸½çµè¡¨æ ¼åœ–ï¼ˆä¿®æ­£å­—é«”å•é¡Œï¼‰
        try:
            fig = plt.figure(figsize=(12, 6))
            plt.axis('off')  # éš±è—è»¸
            
            # æº–å‚™çµ±è¨ˆæ•¸æ“šï¼Œé¿å…ä½¿ç”¨ç‰¹æ®Šç¬¦è™Ÿ
            stats_data = []
            for name in names:
                errors = all_errors[name]
                stats_row = [
                    name,
                    f"{np.mean(errors):.3f}",
                    f"{np.median(errors):.3f}",
                    f"{np.std(errors):.3f}",
                    f"{np.percentile(errors, 25):.3f}",
                    f"{np.percentile(errors, 75):.3f}",
                    f"{np.percentile(errors, 90):.3f}",
                    f"{np.sum(errors <= 1.0)/len(errors)*100:.1f}",
                    f"{np.sum(errors <= 2.0)/len(errors)*100:.1f}",
                    f"{np.sum(errors <= 3.0)/len(errors)*100:.1f}"
                ]
                stats_data.append(stats_row)
            
            # ä¿®æ”¹è¡¨æ ¼æ¨™é¡Œï¼Œé¿å…ä½¿ç”¨ â‰¤ ç¬¦è™Ÿ
            headers = ['æ¨¡å‹', 'å¹³å‡å€¼', 'ä¸­ä½æ•¸', 'æ¨™æº–å·®', 'Q25', 'Q75', 'P90', '<1m', '<2m', '<3m']
            
            # å‰µå»ºè¡¨æ ¼
            table = plt.table(cellText=stats_data, colLabels=headers, 
                             cellLoc='center', loc='center',
                             colColours=['lightgray']*len(headers))
            
            table.auto_set_font_size(False)
            table.set_fontsize(10)
            table.scale(1, 2)  # èª¿æ•´è¡¨æ ¼å¤§å°
            
            # ç‚ºä¸åŒæ¨¡å‹è¡Œè‘—è‰²
            for i in range(len(stats_data)):
                for j in range(len(headers)):
                    if j == 0:  # æ¨¡å‹åç¨±åˆ—
                        table[(i+1, j)].set_facecolor(colors[i % len(colors)])
                        table[(i+1, j)].set_alpha(0.3)
            
            plt.title(f'ä½ç½®é æ¸¬èª¤å·®çµ±è¨ˆç¸½çµ - {scenario_name}', fontsize=14, pad=20)
            plt.tight_layout()
            
            # ä½¿ç”¨ try-except è™•ç†ä¿å­˜éç¨‹ä¸­çš„å­—é«”å•é¡Œ
            try:
                plt.savefig(os.path.join(output_dir, f'error_statistics_table_{scenario_name.replace(" ", "_")}.svg'), format='svg', bbox_inches='tight')
            except Exception as font_error:
                print(f"è¡¨æ ¼ä¿å­˜æ™‚å­—é«”å•é¡Œ: {font_error}ï¼Œå˜—è©¦ä½¿ç”¨åŸºæœ¬å­—é«”")
                # é‡è¨­å­—é«”ç‚ºæ›´åŸºæœ¬çš„é¸é …
                plt.rcParams['font.family'] = ['Arial', 'sans-serif']
                plt.savefig(os.path.join(output_dir, f'error_statistics_table_{scenario_name.replace(" ", "_")}.svg'), format='svg', bbox_inches='tight')
        except Exception as e:
            print(f"çµ±è¨ˆè¡¨æ ¼åœ–ç”Ÿæˆå¤±æ•—: {e}")
        finally:
            plt.close(fig)  # æ˜ç¢ºé—œé–‰ç‰¹å®šåœ–è¡¨

    def generate_cross_scenario_charts(self, full_results, output_dir):
        """ç”Ÿæˆè·¨æƒ…å¢ƒçš„æ¯”è¼ƒåœ–è¡¨"""
        # åœ¨é–‹å§‹å‰é—œé–‰æ‰€æœ‰åœ–è¡¨
        plt.close('all')
        
        scenarios = list(full_results.keys())
        all_models = set()
        for results in full_results.values():
            all_models.update(results.keys())
        all_models = sorted(list(all_models))

        # ç©©å¥æ€§æ¸¬è©¦ - å»ºç¯‰ç‰©æº–ç¢ºç‡
        try:
            fig = plt.figure(figsize=(15, 10))
            scenario_data = {}
            for model in all_models:
                accuracies = []
                for scenario in scenarios:
                    if model in full_results[scenario]:
                        accuracies.append(full_results[scenario][model]['building_accuracy'] * 100)
                    else:
                        accuracies.append(0)
                scenario_data[model] = accuracies

            x = np.arange(len(scenarios))
            width = 0.15
            colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
            
            for i, (model, accuracies) in enumerate(scenario_data.items()):
                plt.bar(x + i * width, accuracies, width, label=model, color=colors[i % len(colors)])

            plt.xlabel('æ¸¬è©¦æƒ…å¢ƒ')
            plt.ylabel('å»ºç¯‰ç‰©åˆ†é¡æº–ç¢ºç‡ (%)')
            plt.title('ä¸åŒæƒ…å¢ƒä¸‹çš„æ¨¡å‹ç©©å¥æ€§æ¸¬è©¦ - å»ºç¯‰ç‰©åˆ†é¡')
            plt.xticks(x + width * (len(all_models) - 1) / 2, scenarios, rotation=15)
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.grid(axis='y', linestyle='--', alpha=0.7)
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'robustness_building_accuracy.svg'), format='svg', bbox_inches='tight')
        except Exception as e:
            print(f"å»ºç¯‰ç‰©ç©©å¥æ€§åœ–ç”Ÿæˆå¤±æ•—: {e}")
        finally:
            plt.close(fig)  # æ˜ç¢ºé—œé–‰ç‰¹å®šåœ–è¡¨

        # ç©©å¥æ€§æ¸¬è©¦ - æ¨“å±¤æº–ç¢ºç‡
        try:
            fig = plt.figure(figsize=(15, 10))
            for i, (model, _) in enumerate(scenario_data.items()):
                floor_accuracies = []
                for scenario in scenarios:
                    if model in full_results[scenario]:
                        floor_accuracies.append(full_results[scenario][model]['floor_accuracy'] * 100)
                    else:
                        floor_accuracies.append(0)
                plt.bar(x + i * width, floor_accuracies, width, label=model, color=colors[i % len(colors)])

            plt.xlabel('æ¸¬è©¦æƒ…å¢ƒ')
            plt.ylabel('æ¨“å±¤åˆ†é¡æº–ç¢ºç‡ (%)')
            plt.title('ä¸åŒæƒ…å¢ƒä¸‹çš„æ¨¡å‹ç©©å¥æ€§æ¸¬è©¦ - æ¨“å±¤åˆ†é¡')
            plt.xticks(x + width * (len(all_models) - 1) / 2, scenarios, rotation=15)
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.grid(axis='y', linestyle='--', alpha=0.7)

            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'robustness_floor_accuracy.svg'), format='svg', bbox_inches='tight')
        except Exception as e:
            print(f"æ¨“å±¤ç©©å¥æ€§åœ–ç”Ÿæˆå¤±æ•—: {e}")
        finally:
            plt.close(fig)  # æ˜ç¢ºé—œé–‰ç‰¹å®šåœ–è¡¨

        # ç©©å¥æ€§æ¸¬è©¦ - ä½ç½®èª¤å·®
        try:
            fig = plt.figure(figsize=(15, 10))
            for i, (model, _) in enumerate(scenario_data.items()):
                position_errors = []
                for scenario in scenarios:
                    if model in full_results[scenario]:
                        position_errors.append(full_results[scenario][model]['position_mean_error'])
                    else:
                        position_errors.append(float('inf'))
                plt.bar(x + i * width, position_errors, width, label=model, color=colors[i % len(colors)])

            plt.xlabel('æ¸¬è©¦æƒ…å¢ƒ')
            plt.ylabel('ä½ç½®é æ¸¬å¹³å‡èª¤å·® (å…¬å°º)')
            plt.title('ä¸åŒæƒ…å¢ƒä¸‹çš„æ¨¡å‹ç©©å¥æ€§æ¸¬è©¦ - ä½ç½®é æ¸¬')
            plt.xticks(x + width * (len(all_models) - 1) / 2, scenarios, rotation=15)
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.grid(axis='y', linestyle='--', alpha=0.7)
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'robustness_position_error.svg'), format='svg', bbox_inches='tight')
        except Exception as e:
            print(f"ä½ç½®ç©©å¥æ€§åœ–ç”Ÿæˆå¤±æ•—: {e}")
        finally:
            plt.close(fig)  # æ˜ç¢ºé—œé–‰ç‰¹å®šåœ–è¡¨

        # æ¨¡å‹ç©©å¥æ€§è©•åˆ†åœ–è¡¨
        self.generate_robustness_score_chart(full_results, output_dir, scenarios, all_models)

    def generate_robustness_score_chart(self, full_results, output_dir, scenarios, all_models):
        """ç”Ÿæˆæ¨¡å‹ç©©å¥æ€§è©•åˆ†"""
        # è¨ˆç®—åŸºæº–æƒ…å¢ƒï¼ˆé€šå¸¸ç‚º 'åŸå§‹è³‡æ–™'ï¼‰çš„æ€§èƒ½
        baseline_scenario = scenarios[0] if scenarios else None
        robustness_scores = {}

        if baseline_scenario is None:
            print("æ²’æœ‰åŸºæº–æƒ…å¢ƒï¼Œç„¡æ³•è¨ˆç®—ç©©å¥æ€§è©•åˆ†ã€‚")
            return

        for model in all_models:
            scores = []
            if model not in full_results[baseline_scenario]:
                # å¦‚æœåŸºæº–æƒ…å¢ƒæ²’æœ‰è©²æ¨¡å‹ï¼Œå…¨éƒ¨è¨­ç‚º0
                scores = [0.0 for _ in scenarios]
            else:
                baseline_building_acc = full_results[baseline_scenario][model]['building_accuracy']
                baseline_floor_acc = full_results[baseline_scenario][model]['floor_accuracy']
                baseline_position_error = full_results[baseline_scenario][model]['position_mean_error']
                for scenario in scenarios:
                    if model in full_results[scenario]:
                        building_acc = full_results[scenario][model]['building_accuracy']
                        floor_acc = full_results[scenario][model]['floor_accuracy']
                        position_error = full_results[scenario][model]['position_mean_error']
                        # ç©©å¥æ€§è©•åˆ†ï¼šåˆ†é¡æº–ç¢ºç‡ç›¸å°ä¿æŒç‡å’Œä½ç½®èª¤å·®ç›¸å°ä¿æŒç‡çš„åŠ æ¬Šå¹³å‡
                        # ä½ç½®èª¤å·®è¶Šä½è¶Šå¥½ï¼Œå› æ­¤ç”¨åŸºæº–/ç•¶å‰
                        score = (
                            0.4 * (building_acc / baseline_building_acc if baseline_building_acc > 0 else 0) +
                            0.3 * (floor_acc / baseline_floor_acc if baseline_floor_acc > 0 else 0) +
                            0.3 * (baseline_position_error / position_error if position_error > 0 else 0)
                        )
                        # é™åˆ¶æœ€å¤§å€¼ç‚º1.0
                        score = min(score, 1.0)
                        scores.append(score)
                    else:
                        scores.append(0.0)
            robustness_scores[model] = scores

        # ç¹ªè£½ç©©å¥æ€§è©•åˆ†åœ–è¡¨
        try:
            plt.figure(figsize=(15, 10))
            width = 0.15
            colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']
            x = np.arange(len(scenarios))  # å®šç¾© x ç‚ºæƒ…å¢ƒç´¢å¼•

            for i, (model, scores) in enumerate(robustness_scores.items()):
                plt.bar(x + i * width, scores, width, label=model, color=colors[i % len(colors)])

            plt.xlabel('æ¸¬è©¦æƒ…å¢ƒ')
            plt.ylabel('ç©©å¥æ€§è©•åˆ† (1.0=åŸºæº–)')
            plt.title('ä¸åŒæƒ…å¢ƒä¸‹çš„æ¨¡å‹ç©©å¥æ€§è©•åˆ†')
            plt.xticks(x + width * (len(robustness_scores) - 1) / 2, scenarios, rotation=15)
            plt.ylim(0, 1.05)
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.grid(axis='y', linestyle='--', alpha=0.7)
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'robustness_scores.svg'), format='svg', bbox_inches='tight')
        except Exception as e:
            print(f"ç©©å¥æ€§è©•åˆ†åœ–ç”Ÿæˆå¤±æ•—: {e}")
        finally:
            plt.close()

    # æ–°å¢ï¼šçµ±ä¸€è¨ˆç®—ç©©å¥æ€§åˆ†æ•¸ï¼ˆä¾›åœ–èˆ‡æ‘˜è¦å…±ç”¨ï¼‰
    def compute_robustness_scores(self, full_results):
        """
        å›å‚³:
          baseline_scenario: åŸºæº–æƒ…å¢ƒåç¨±
          scenarios: æƒ…å¢ƒåˆ—è¡¨ï¼ˆæœ‰åºï¼‰
          all_models: æ¨¡å‹åç¨±åˆ—è¡¨ï¼ˆæ’åºï¼‰
          robustness_scores: dict[model] -> list[score per scenario]
        """
        scenarios = list(full_results.keys())
        if not scenarios:
            return None, [], [], {}

        # å„ªå…ˆä½¿ç”¨ã€ŒåŸå§‹è³‡æ–™ã€ç‚ºåŸºæº–ï¼Œå¦å‰‡å–ç¬¬ä¸€å€‹
        baseline_scenario = 'åŸå§‹è³‡æ–™' if 'åŸå§‹è³‡æ–™' in scenarios else scenarios[0]

        # è’é›†æ‰€æœ‰æ¨¡å‹
        all_models = set()
        for results in full_results.values():
            all_models.update(results.keys())
        all_models = sorted(list(all_models))

        robustness_scores = {}
        for model in all_models:
            scores = []
            # è‹¥åŸºæº–æ²’æœ‰è©²æ¨¡å‹ï¼Œå¾ŒçºŒçš†ç‚º 0
            if model not in full_results.get(baseline_scenario, {}):
                scores = [0.0 for _ in scenarios]
            else:
                baseline_building_acc = full_results[baseline_scenario][model]['building_accuracy']
                baseline_floor_acc = full_results[baseline_scenario][model]['floor_accuracy']
                baseline_position_error = full_results[baseline_scenario][model]['position_mean_error']
                for scenario in scenarios:
                    if model in full_results[scenario]:
                        building_acc = full_results[scenario][model]['building_accuracy']
                        floor_acc = full_results[scenario][model]['floor_accuracy']
                        position_error = full_results[scenario][model]['position_mean_error']
                        score = (
                            0.4 * (building_acc / baseline_building_acc if baseline_building_acc > 0 else 0) +
                            0.3 * (floor_acc / baseline_floor_acc if baseline_floor_acc > 0 else 0) +
                            0.3 * (baseline_position_error / position_error if position_error > 0 else 0)
                        )
                        score = min(score, 1.0)
                        scores.append(score)
                    else:
                        scores.append(0.0)
            robustness_scores[model] = scores

        return baseline_scenario, scenarios, all_models, robustness_scores

    # æ–°å¢ï¼šè¼¸å‡ºç©©å¥æ€§æ‘˜è¦ Markdown
    def generate_robustness_summary(self, full_results, output_dir):
        """
        ç”Ÿæˆ robustness_summary.mdï¼ŒåŒ…å«ï¼š
        - è©•åˆ†æ¨™æº–èˆ‡æ¸¬è©¦æ–¹æ³•
        - æ¨¡å‹ç©©å¥æ€§æ’åï¼ˆå¹³å‡åˆ†æ•¸ï¼‰
        - ç²¾é¸æƒ…å¢ƒåˆ†æ•¸è¡¨
        - é—œéµç™¼ç¾èˆ‡æ™‚é–“æˆ³
        """
        baseline_scenario, scenarios, all_models, robustness_scores = self.compute_robustness_scores(full_results)
        if not scenarios:
            print("æ²’æœ‰æƒ…å¢ƒå¯ç”Ÿæˆç©©å¥æ€§æ‘˜è¦ã€‚")
            return

        # å–å¾—æ¸¬è©¦æ¬¡æ•¸ï¼ˆå¾ä»»ä¸€çµæœå–å‡ºï¼‰
        try:
            any_result = next(iter(next(iter(full_results.values())).values()))
            num_trials = any_result.get('num_trials', 1)
        except Exception:
            num_trials = 1

        # è¨ˆç®—æ¯å€‹æ¨¡å‹çš„å¹³å‡åˆ†æ•¸ï¼ˆæ’é™¤åŸºæº–æƒ…å¢ƒï¼‰
        try:
            baseline_idx = scenarios.index(baseline_scenario)
        except ValueError:
            baseline_idx = 0

        model_avg = {}
        for model in all_models:
            scores = robustness_scores.get(model, [])
            if not scores:
                model_avg[model] = 0.0
                continue
            scores_ex_baseline = [s for i, s in enumerate(scores) if i != baseline_idx]
            avg = float(np.mean(scores_ex_baseline)) if scores_ex_baseline else float(np.mean(scores))
            model_avg[model] = avg

        # æ’åï¼ˆç”±é«˜åˆ°ä½ï¼‰
        ranking = sorted(model_avg.items(), key=lambda x: x[1], reverse=True)

        # ç²¾é¸æƒ…å¢ƒï¼ˆè‹¥ä¸å­˜åœ¨å‰‡å¿½ç•¥ï¼‰
        preferred = ['åŸå§‹è³‡æ–™', 'é«˜æ–¯é›œè¨Š 5dB', 'è¨­å‚™æ•…éšœ 10%', 'è¨­å‚™æ•…éšœ 35%', 'é›œè¨Š 5dB + æ•…éšœ 10%', 'é›œè¨Š 10dB + æ•…éšœ 20%']
        selected_scenarios = [s for s in preferred if s in scenarios]
        if not selected_scenarios:
            selected_scenarios = scenarios[:min(6, len(scenarios))]

        # è¨ˆç®—æ¯å€‹æƒ…å¢ƒçš„å¹³å‡åˆ†æ•¸ï¼ˆç”¨æ–¼æ‰¾å‡ºæœ€å…·æŒ‘æˆ°æ€§æƒ…å¢ƒï¼Œæ’é™¤åŸºæº–ï¼‰
        scenario_avg = {}
        for i, sc in enumerate(scenarios):
            vals = [robustness_scores[m][i] for m in all_models if len(robustness_scores[m]) > i]
            scenario_avg[sc] = float(np.mean(vals)) if vals else 0.0
        toughest_scenario = min(
            ((sc, v) for sc, v in scenario_avg.items() if sc != baseline_scenario),
            key=lambda x: x[1],
            default=(scenarios[0], scenario_avg.get(scenarios[0], 0.0))
        )

        # æª”æ¡ˆè¼¸å‡º
        out_path = os.path.join(output_dir, 'robustness_summary.md')
        now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        with open(out_path, 'w', encoding='utf-8') as f:
            f.write("# æ¨¡å‹ç©©å¥æ€§è©•åˆ†æ‘˜è¦\n\n")
            f.write("æœ¬æ‘˜è¦åŸºæ–¼ä¸åŒè³‡æ–™æå£æƒ…å¢ƒä¸‹çš„æ¨¡å‹æ€§èƒ½ä¿æŒç‡è¨ˆç®—ç©©å¥æ€§è©•åˆ†ã€‚\n\n")
            f.write("**è©•åˆ†æ¨™æº–**ï¼š\n")
            f.write("- 1.0ï¼šå®Œç¾ä¿æŒåŸºæº–æ€§èƒ½\n")
            f.write("- 0.8-1.0ï¼šå„ªç§€çš„ç©©å¥æ€§\n")
            f.write("- 0.6-0.8ï¼šè‰¯å¥½çš„ç©©å¥æ€§\n")
            f.write("- 0.4-0.6ï¼šä¸€èˆ¬çš„ç©©å¥æ€§\n")
            f.write("- <0.4ï¼šè¼ƒå·®çš„ç©©å¥æ€§\n\n")
            f.write("**æ¸¬è©¦æ–¹æ³•**ï¼š\n")
            f.write(f"- æ¯å€‹æƒ…å¢ƒé€²è¡Œ {num_trials} æ¬¡ç¨ç«‹æ¸¬è©¦å–å¹³å‡å€¼\n")
            f.write("- åŸå§‹è³‡æ–™çš„å¤šæ¬¡æ¸¬è©¦ç”¨æ–¼è©•ä¼°æ¨¡å‹å…§éƒ¨éš¨æ©Ÿæ€§å’Œæ•¸å€¼ç©©å®šæ€§\n")
            f.write("- æå£æƒ…å¢ƒçš„å¤šæ¬¡æ¸¬è©¦ç”¨æ–¼ç²å¾—æ›´å¯é çš„ç©©å¥æ€§è©•ä¼°\n\n")
            f.write("- **æ¸¬è©¦æ–¹æ³•èªªæ˜**ï¼šæ‰€æœ‰æƒ…å¢ƒéƒ½é€²è¡Œç›¸åŒæ¬¡æ•¸çš„æ¸¬è©¦ï¼Œç¢ºä¿çµ±è¨ˆçµæœçš„å¯é æ€§\n")
            f.write("  - åŸå§‹è³‡æ–™ï¼šè©•ä¼°æ¨¡å‹é æ¸¬çš„ä¸€è‡´æ€§å’Œæ•¸å€¼ç©©å®šæ€§\n")
            f.write("  - æå£æƒ…å¢ƒï¼šè©•ä¼°åœ¨ä¸åŒéš¨æ©Ÿæå£æ¨¡å¼ä¸‹çš„å¹³å‡æ€§èƒ½\n")

            f.write("## æ¨¡å‹ç©©å¥æ€§æ’å\n\n")
            for i, (m, avg) in enumerate(ranking, start=1):
                level = "éœ€æ”¹é€²"
                f.write(f"{i}. **{m}**ï¼šå¹³å‡ç©©å¥æ€§è©•åˆ† {avg:.3f} ({level})\n")
            f.write("\n")

            f.write("## å„æƒ…å¢ƒè©³ç´°è©•åˆ†\n\n")
            # è¡¨é ­
            f.write("|                | " + " | ".join([f"{sc}" for sc in selected_scenarios]) + " |\n")
            f.write("|:---------------|" + "|".join([":" + "-"*(max(3, len(sc))) for sc in selected_scenarios]) + "|\n")
            # å„æ¨¡å‹åˆ—
            for m in all_models:
                f.write(f"| {m} ")
                for sc in selected_scenarios:
                    idx = scenarios.index(sc)
                    val = robustness_scores[m][idx] if len(robustness_scores[m]) > idx else 0.0
                    f.write(f"| {val:.3f} ")
                f.write("|\n")

            f.write("\n## é—œéµç™¼ç¾\n\n")
            if ranking:
                f.write(f"- æœ€ç©©å¥æ¨¡å‹ï¼š{ranking[0][0]}ï¼ˆå¹³å‡è©•åˆ†ï¼š{ranking[0][1]:.3f}ï¼‰\n")
            f.write(f"- æœ€å…·æŒ‘æˆ°æ€§æƒ…å¢ƒï¼š{toughest_scenario[0]}ï¼ˆå¹³å‡è©•åˆ†ï¼š{toughest_scenario[1]:.3f}ï¼‰\n")
            f.write("- çµ±è¨ˆå¯é æ€§ï¼šå¤šæ¬¡æ¸¬è©¦å¯é™ä½å–®æ¬¡éš¨æ©Ÿæ€§çš„å½±éŸ¿ï¼Œæé«˜çµè«–å¯ä¿¡åº¦\n\n")
            f.write("---\n")
            f.write(f"*å ±å‘Šç”Ÿæˆæ™‚é–“ï¼š{now_str}*\n")
            f.write(f"*æ¸¬è©¦è¨­å®šï¼šæ¯æƒ…å¢ƒ {num_trials} æ¬¡ç¨ç«‹æ¸¬è©¦å–å¹³å‡*\n")

        print(f"ç©©å¥æ€§æ‘˜è¦å·²ç”Ÿæˆè‡³: {out_path}")
        
def main():
    """ä¸»å‡½æ•¸"""
    print("=== é–‹å§‹æ¨¡å‹æ¯”è¼ƒå’Œç©©å¥æ€§æ¸¬è©¦ ===")
    
    comparator = ModelComparison()
    comparator.compare_models()
    
    print("=== æ¯”è¼ƒå’Œæ¸¬è©¦å®Œæˆ ===")

if __name__ == '__main__':
    main()